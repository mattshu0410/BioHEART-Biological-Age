---
title: "Resilience Cohort in BioHEART"
subtitle: "BioHEART"
author: "Daniel Cheng, Matthew Shu"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
toc-title: "Table of Contents"
vignette: >
  %\VignetteIndexEntry{Creating Pretty Documents from R Markdown - The Cayman Theme}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
```{r, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(dplyr)
library(glmnet)
library(caret)
library(corrplot)
library(naniar)
library(factoextra)
library(kableExtra)
library(MultiAssayExperiment)
library(boot)
library(CVrisk)
library(limma)
library(plotly)
library(Glimma)
library(ggrepel)
library(pscl)
library(bestNormalize)
library(gridExtra)
library(RiskScorescvd)
```

# Biological Age

```{r, results='hide', warning=FALSE, message=FALSE}
load("MultiAssayExperiment_20220816.RData")


data_folder = "M:/Github-Version-Control-Projects/BioHEART-Summer-Project/Data"
BioHRT_dat = readxl::read_excel(file.path(data_folder, "DL4_20230831-BL_Imaging-Omics-20240116_SHU.xlsx"), "nolabel")
load("FRS_data.RData")
```

```{r}
BioHRT_dat  %>% filter(disc_1000 == 1) %>%
  filter(is.na(tc) | is.na(hdl)) %>%
  select(record_id, tc, hdl)

pheno_df %>%
  filter(is.na(tc) | is.na(hdl)) %>%
  select(record_id, tc, hdl) %>%
  pull(record_id)

BioHRT_dat %>% filter(disc_1000 == 1)
```

```{r}
head(BioHRT_dat)
BioHRT_dat = BioHRT_dat %>%
  rename(gender = sex)

# Print record_id with no maximum output

BioHRT_dat %>% select(record_id, cacs, cacs_pct, gender) %>% write.csv("record_id.csv", row.names = FALSE)
```


## Ensemble Model of Resilience

### Calculate Scores

Relevant Variables from BioHEART

* `race` (white, aa, chinese, or hispanic) 
* `age` (years) 
* `totchol` (mg/dL) \<- ours is in mmol/L hdl (mg/dL) 
* `sbp` (mmHg) 
* `bp_med` (Y/N)
* `ace_i`
* `bblocker`
* `diur_loop`
* `diur_k`
* `diur_unk`
* `ccb smoker` (Y/N) 
* `diabetes` (Y/N)
* `bmi` 
* `lipid_med` (Y/N)
* `statin`
* `fh_heartattack` (Y/N)
* `cac` (Agatson)

#### SCORE2

* The methods for calculating the SCORE2 and relevant coefficients can be found in the supplementary material located at the following link.
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8248998/
* The SCORE2 risk score is specifically for people below 70 or below. There is a separate set of coefficients for people older than 70.
* There are region and sex-specific recalibration scales; in this situation we have assumed Australia is a Low Risk Region.



```{r}
# sbp -> mmHg
# tchol -> mmol/L
# hdl -> mmol/L
# gender -> 'male' or 'female'

SCORE2_10yr= function(gender, age, curr_smok, sbp, dm, tchol, hdl) {
  # Transformation of Variables (Supplementary Methods Table 2)
  cage = (age-60)/5
  csbp = (sbp-120)/20
  ctchol = (tchol-6)/1
  chdl = (hdl-1.3)/0.5
  dm = as.numeric(dm)
  curr_smok = as.numeric(dm)
  
  # Rescaling Factors based on Low Risk Region (Supplementary Methods Table 3)
  male_RF = c(-0.5699, 0.7476)
  female_RF = c(-0.7380, 0.7019)
  
  # Linear Predictor + Calibration (Supplementary Methods Table 1)
  # Male
  if (gender == 'male') {
    beta_x = 0.3742*cage + 0.1458*ctchol - 0.2698*chdl + 0.2777*csbp + 
    0.6457*dm + 0.6012*curr_smok - 0.0281*cage*ctchol + 0.0426*cage*chdl +
    - 0.0255*cage*csbp - 0.0983*cage*dm - 0.0755*cage*curr_smok
    
    ten_yr_risk = 1-0.9605^(exp(beta_x))
    
    estimate = 1-exp(-exp(male_RF[1]+male_RF[2]*log(-log(1-ten_yr_risk))))
    
  # Female
  } else if (gender == 'female'){
    beta_x = 0.4648*cage + 0.1002*ctchol - 0.2606*chdl + 0.3131*csbp + 
    0.8096*dm + 0.7744*curr_smok - 0.0226*cage*ctchol + 0.0613*cage*chdl +
    - 0.0277*cage*csbp - 0.1272*cage*dm - 0.1088*cage*curr_smok
    
    ten_yr_risk = 1-0.9776^(exp(beta_x))
    
    estimate = 1-exp(-exp(female_RF[1]+female_RF[2]*log(-log(1-ten_yr_risk))))
  }
  
  return(estimate*100)
  
  
}

```

#### SCORE2-OP

* The methods for calculating the SCORE2-OP and relevant coefficients can be found in the supplementary material located at the following link.
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8248997/
* The SCORE2-OP risk score is specifically for people above 70.
* There are region and sex-specific recalibration scales; in this situation we have assumed Australia is a Low Risk Region.
```{r}

# ONLY FOR ABOVE 70 years old
# Assumes a low-risk region
# sbp -> mmHg
# tchol -> mmol/L
# hdl -> mmol/L
# gender -> 'male' or 'female'

SCORE2OP_10yr= function(gender, age, curr_smok, sbp, dm, tchol, hdl) {
  # Transformation of Variables (Supplementary Methods Table 3)
  cage = age-73
  csbp = sbp-150
  ctchol = tchol-6
  chdl = hdl-1.4
  dm = as.numeric(dm)
  curr_smok = as.numeric(dm)
  
  # Rescaling Factors based on Low Risk Region (Supplementary Methods Table 1)
  male_RF = c(-0.34, 1.19)
  female_RF = c(-0.52, 1.01)
  
  # Linear Predictor + Calibration (Supplementary Methods Table 3)
  # Male
  if (gender == 'male') {
    beta_x = 0.0634*cage + 0.0850*ctchol - 0.3564*chdl + 0.0094*csbp + 
    0.4245*dm + 0.3524*curr_smok - 0.0073*cage*ctchol + 0.0091*cage*chdl +
    - 0.0005*cage*csbp - 0.0174*cage*dm - 0.0247*cage*curr_smok
    
    ten_yr_risk = 1-0.7576^(exp(beta_x-0.0929))
    
    estimate = 1-exp(-exp(male_RF[1]+male_RF[2]*log(-log(1-ten_yr_risk))))
    
  # Female
  } else if (gender == 'female'){
    beta_x = 0.0789*cage + 0.0605*ctchol - 0.3040*chdl + 0.0102*csbp + 
    0.6010*dm + 0.4921*curr_smok - 0.0009*cage*ctchol + 0.0154*cage*chdl +
    - 0.0004*cage*csbp - 0.0107*cage*dm - 0.0255*cage*curr_smok
    
    
    ten_yr_risk = 1-0.8082^(exp(beta_x-0.229))
    
    estimate = 1-exp(-exp(female_RF[1]+female_RF[2]*log(-log(1-ten_yr_risk))))
  }
  
  return(estimate*100)
  
  
}

```


#### All Score Calculations

We have decided to calculate the following CVD Risk Scores for all BioHEART subjects. There are certain limitations of each score where important re-coding decisions were made on the BioHEART data. These limitations are denoted below.

* FRS
* ASCVD (Restricted)
  + 20 < age < 79 
  + 130 < totchol < 320
  + 20 < hdl < 100
  + 90 < sbp < 200
  + White, African American, Other
* MESA CHD (Limited Ethnicities)
  + White, African American, Chinese, American
* SCORE2

BioHEART Ethnicity Coding (ethcat)

* 1 = European 
* 2 = Indigenous Australia 
* 3 = Polynesian 
* 4 = African 
* 5 = Asian 
* 6 = Indian 
* 7 = Middle Eastern
* 8 = Hispanic
* 9 = Other / Dual Ethnicity

Important Recoding Decisions
* For ACCAHA, all other ethnicities were grouped under "Other". 
* For MESA, Polynesians, Middle Eastern and any Other Ethnicities were classified as White.

```{r}

pheno_df = BioHRT_dat %>%
  # IMPORTANT: FILTERS ONLY DISCOVERY 1000
  filter(disc_1000 == 1) %>%
  # remove where gender or cac or cacs_pct not recorded
  drop_na(gender, cacs, cacs_pct) %>%
  # tc and hdl non-zero
  filter(!is.na(tc) | !is.na(hdl)) %>%
  # missing value encoded as .
  filter(cacs_pct != ".") %>%
  # limits of ascvd limited between 30 and 74
  #filter((age<=79) & (age>=20)) %>%
  mutate(
    # refactor gender
    gender = case_when(
      gender==1 ~ 'male',
      gender==2 ~ 'female'
      ),
    # convert from mmol/L to mg/dL
    HDL_mgdl = hdl*38.67,
    Chol_mgdl = tc*38.67,
    # new variable presence or absence of blood pressure meds
    bp_med = case_when(
      ace_arb == 1 ~ 1,
      bblocker == 1 ~ 1,
      diuretic == 1 ~ 1,
      ccb == 1 ~ 1,
      TRUE ~ 0
    ),
    # new variable presence or absence of lipid lowering meds
    lipid_med = case_when(
      statin == 1 ~ 1,
      ezetimibe == 1 ~ 1,
      fibrate == 1 ~ 1,
      niacin == 1 ~ 1,
      babr == 1 ~ 1,
      plant_sterol == 1 ~ 1,
      lipid_lowering_unknown == 1 ~ 1,
      TRUE ~ 0
    ),
    # assume no history of IHD if NA
    fh_ihd = case_when(
      fh_ihd == 1 ~ 1,
      fh_ihd == 0 ~ 0,
      is.na(fh_ihd) ~ 0
    ),
    # CACS as number
    cacs = as.numeric(cacs),
    cacs_pct = as.numeric(cacs_pct),
    # ACCAHA Ethnicity
    accaha_eth = case_when(
      ethcat == 1 ~ 'white',
      ethcat == 4 ~ 'aa',
      TRUE ~ 'other'
    ),
    # Unresolved: MESA only contains 4 ethnicity categories, what do we do with other?
    mesa_eth = case_when(
      ethcat == 1 ~ 'white',
      ethcat == 2 ~ 'aa',
      ethcat == 3 ~ 'white', # contentious Polynesian
      ethcat == 4 ~ 'aa',
      ethcat == 5 ~ 'chinese',
      ethcat == 7 ~ 'white',
      ethcat == 8 ~ 'hispanic',
      ethcat == 9 ~ 'white', # contentious mixed/Other
      TRUE ~ 'white' # if NA assume white
    ),
    
  )

pheno_df = pheno_df %>%
  rowwise() %>%
  mutate(
    # FRS Score
    ascvd_10y_frs = ascvd_10y_frs(gender, age, HDL_mgdl, Chol_mgdl, sbp, bp_med, curr_smok, cvhx_dm),
    # ASCVD (Pooled Cohort Equations - USA) w/ Requirements
    # 20 < age < 79 
    # 130 < totchol < 320
    # 20 < hdl < 100
    # 90 < sbp < 200
    ascvd_10y_accaha = ascvd_10y_accaha(accaha_eth, gender, age, Chol_mgdl, HDL_mgdl, sbp, bp_med, curr_smok, cvhx_dm),
    # MESA CHD
    chd_10y_mesa = chd_10y_mesa(mesa_eth, gender, age, Chol_mgdl, HDL_mgdl,lipid_med, sbp, bp_med, curr_smok, cvhx_dm, fh_ihd),
    # MESA CHD w/ CAC
    chd_10y_mesa_cac = chd_10y_mesa_cac(mesa_eth, gender, age, Chol_mgdl, HDL_mgdl,lipid_med, sbp, bp_med, curr_smok, cvhx_dm, fh_ihd, cacs),
    # SCORE2 <= 70 year olds
    SCORE2_10yr = SCORE2_10yr(gender, age, curr_smok, sbp, cvhx_dm, tc, hdl),
    # SCORE2-OP > 70 year olds
    SCORE2OP_10yr= SCORE2OP_10yr(gender, age, curr_smok, sbp, cvhx_dm, tc, hdl),
    # New Package
    # SCORE2 <= 70 year olds
    SCORE2_new = SCORE2(Risk.region = "Low", age, gender, curr_smok, sbp, cvhx_dm, tc, hdl, FALSE),
    
    ) %>%
  mutate(
    # Use the right SCORE2 based on age
    SCORE2 = case_when(
      age <= 70 ~ SCORE2_10yr,
      age > 70 ~ SCORE2OP_10yr
    )
  )

score_df = pheno_df %>%
  dplyr::select(record_id, cacs, cacs_pct, ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2, SCORE2_new)
# Picked MESA without CAC since CAC will be the y-axis when calculating residuals
# 112 missing values out of range but no particular pattern in its distribution


# For the Paper
# ASCVD
BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  mutate(Chol_mgdl = tc*38.67) %>%
  filter(Chol_mgdl < 130 | Chol_mgdl > 320)

BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  filter(age < 20 | age > 79)

BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  mutate(HDL_mgdl = hdl*38.67) %>%
  filter(HDL_mgdl < 20 | HDL_mgdl > 100)

BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  filter(sbp < 90 | sbp > 200)

# FRS
BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  filter(age <= 30)

BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  filter(disc_1000 == 1)

BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  filter(is.na(ascvd_10y_accaha)) %>%
  select(gender, age, HDL_mgdl, Chol_mgdl, sbp, bp_med, curr_smok, cvhx_dm)


```

Just ASCVD

```{r}

pheno_df = BioHRT_dat %>%
  filter(disc_1000 == 1) %>%
  # remove where gender or cac or cacs_pct not recorded
  drop_na(gender, cacs, cacs_pct) %>%
  # tc and hdl non-zero
  filter(!is.na(tc) | !is.na(hdl)) %>%
  # missing value encoded as .
  filter(cacs_pct != ".") %>%
  # limits of ascvd limited between 30 and 74
  #filter((age<=79) & (age>=20)) %>%
  mutate(
    # refactor gender
    gender = case_when(
      gender==1 ~ 'male',
      gender==2 ~ 'female'
      ),
    # convert from mmol/L to mg/dL
    HDL_mgdl = hdl*38.67,
    Chol_mgdl = tc*38.67,
    # new variable presence or absence of blood pressure meds
    bp_med = case_when(
      ace_arb == 1 ~ 1,
      bblocker == 1 ~ 1,
      diuretic == 1 ~ 1,
      ccb == 1 ~ 1,
      TRUE ~ 0
    ),
    # new variable presence or absence of lipid lowering meds
    lipid_med = case_when(
      statin == 1 ~ 1,
      ezetimibe == 1 ~ 1,
      fibrate == 1 ~ 1,
      niacin == 1 ~ 1,
      babr == 1 ~ 1,
      plant_sterol == 1 ~ 1,
      lipid_lowering_unknown == 1 ~ 1,
      TRUE ~ 0
    ),
    # assume no history of IHD if NA
    fh_ihd = case_when(
      fh_ihd == 1 ~ 1,
      fh_ihd == 0 ~ 0,
      is.na(fh_ihd) ~ 0
    ),
    # CACS as number
    cacs = as.numeric(cacs),
    cacs_pct = as.numeric(cacs_pct),
    # ACCAHA Ethnicity
    accaha_eth = case_when(
      ethcat == 1 ~ 'white',
      ethcat == 4 ~ 'aa',
      TRUE ~ 'other'
    ),
    # Unresolved: MESA only contains 4 ethnicity categories, what do we do with other?
    mesa_eth = case_when(
      ethcat == 1 ~ 'white',
      ethcat == 2 ~ 'aa',
      ethcat == 3 ~ 'white', # contentious Polynesian
      ethcat == 4 ~ 'aa',
      ethcat == 5 ~ 'chinese',
      ethcat == 7 ~ 'white',
      ethcat == 8 ~ 'hispanic',
      ethcat == 9 ~ 'white', # contentious mixed/Other
      TRUE ~ 'white' # if NA assume white
    ),
    
  )

# pheno_df = pheno_df %>%
#   rowwise() %>%
#   mutate(
# 
#     # ASCVD (Pooled Cohort Equations - USA) w/ Requirements
#     # 20 < age < 79 
#     # 130 < totchol < 320
#     # 20 < hdl < 100
#     # 90 < sbp < 200
#     ascvd_10y_accaha = ascvd_10y_accaha(accaha_eth, gender, age, Chol_mgdl, HDL_mgdl, sbp, bp_med, curr_smok, cvhx_dm),
#     )

pheno_df = pheno_df %>%
  rowwise() %>%
  mutate(
    # FRS Score
    ascvd_10y_frs = ascvd_10y_frs(gender, age, HDL_mgdl, Chol_mgdl, sbp, bp_med, curr_smok, cvhx_dm),
  )

score_df = pheno_df %>%
  dplyr::select(record_id, cacs, cacs_pct, ascvd_10y_frs)
# Picked MESA without CAC since CAC will be the y-axis when calculating residuals
# 112 missing values out of range but no particular pattern in its distribution


# Drop all NA across all scores
score_df = score_df %>% drop_na(ascvd_10y_frs)

```

Missing Value Analysis

```{r}


missing_score_record_id = pheno_df %>%
  filter(is.na(ascvd_10y_frs) | is.na(ascvd_10y_accaha)) %>%
  pull(record_id)

pheno_df %>% filter(record_id == 1209) %>% select(gender, age, HDL_mgdl, Chol_mgdl, sbp, bp_med, curr_smok, cvhx_dm)

pheno_df %>%
  filter(
    !(age > 79 | Chol_mgdl < 130 | Chol_mgdl > 320 | HDL_mgdl < 20 | HDL_mgdl > 100 | sbp < 90) & 
    !(age < 30 | age > 74)
  )

# Number of participants removed due to age > 79
removed_age_ascvd <- pheno_df %>%
  filter(age > 79)
cat("Removed due to age > 79 (ASCVD):", nrow(removed_age_ascvd), "\n")

# Number of participants removed due to total cholesterol (Chol_mgdl < 130 or Chol_mgdl > 320)
removed_chol <- pheno_df %>%
  filter(Chol_mgdl < 130 | Chol_mgdl > 320)
cat("Removed due to total cholesterol (Chol_mgdl < 130 or > 320):", nrow(removed_chol), "\n")

# Number of participants removed due to HDL_mgdl < 20 or HDL_mgdl > 100
removed_hdl <- pheno_df %>%
  filter(HDL_mgdl < 20 | HDL_mgdl > 100)
cat("Removed due to HDL_mgdl < 20 or > 100:", nrow(removed_hdl), "\n")

# Number of participants removed due to sbp < 90
removed_sbp <- pheno_df %>%
  filter(sbp < 90)
cat("Removed due to sbp < 90:", nrow(removed_sbp), "\n")

# Number of participants removed due to age < 30 (FRS)
removed_age_frs_under_30 <- pheno_df %>%
  filter(age < 30)
cat("Removed due to age < 30 (FRS):", nrow(removed_age_frs_under_30), "\n")

# Number of participants removed due to age > 74 (FRS)
removed_age_frs_above_74 <- pheno_df %>%
  filter(age > 74)
cat("Removed due to age > 74 (FRS):", nrow(removed_age_frs_above_74), "\n")

# Check overlap: Participants removed from both ASCVD and FRS due to exclusion criteria
overlap <- pheno_df %>%
  filter(
    (age > 79 | Chol_mgdl < 130 | Chol_mgdl > 320 | HDL_mgdl < 20 | HDL_mgdl > 100 | sbp < 90 | age < 30 | age > 74)
  ) %>% pull(record_id)
cat("Overlap of participants removed due to both ASCVD and FRS criteria:", nrow(overlap), "\n")


setdiff(missing_score_record_id, overlap)
```
```{r}
cohort = pheno_df %>%
  mutate(
    removed_age_ascvd = ifelse(is.na(age) | age > 79, TRUE, FALSE),
    removed_chol = ifelse(is.na(Chol_mgdl) | Chol_mgdl < 130 | Chol_mgdl > 320, TRUE, FALSE),
    removed_hdl = ifelse(is.na(HDL_mgdl) | HDL_mgdl < 20 | HDL_mgdl > 100, TRUE, FALSE),
    removed_sbp = ifelse(is.na(sbp) | sbp < 90, TRUE, FALSE),
    removed_age_frs_under_30 = ifelse(is.na(age) | age < 30, TRUE, FALSE),
    removed_age_frs_above_74 = ifelse(is.na(age) | age > 74, TRUE, FALSE)
  ) %>%
  select(age, Chol_mgdl, HDL_mgdl, sbp, record_id, removed_age_ascvd, removed_chol, removed_hdl, removed_sbp, removed_age_frs_under_30, removed_age_frs_above_74)
  # filter(
  #   !removed_age_ascvd &
  #   !removed_chol &
  #   !removed_hdl &
  #   !removed_sbp &
  #   !removed_age_frs_under_30 &
  #   !removed_age_frs_above_74
  # )

write_csv(cohort, "M:\\Github-Version-Control-Projects\\BioHEART-Biological-Age\\cohort.csv")
```

### Cluster Analysis

```{r}
hist()
tdf = score_df %>%
  drop_na(chd_10y_mesa) %>%
  mutate(ordernorm_chd_10y_mesa = orderNorm(chd_10y_mesa)$x.t) %>%
  mutate(ordernorm_cacs = orderNorm(cacs)$x.t)

hist(tdf$ordernorm_cacs) 

```




After calculation of the risk scores, there appears to be some missing values. On further inspection of the ASCVD 10YR ACCAHA score calculator it appears that the total cholesterol value needs to be above 130 mg/dL for the score calculator to work (limited by the cohort that this risk score was trained on).

* This represents 1.7% of the data 
* There seems to be a good proportion of subjects who are missed because of low Total Cholesterol


```{r, warning=FALSE}
score_df %>%
  mutate(
    na = case_when(
      is.na(ascvd_10y_accaha) ~ TRUE,
      !is.na(ascvd_10y_accaha) ~ FALSE
    )
  ) %>%
  #filter(na == TRUE) %>%
  ggplot() +
  aes(x = cacs_pct, y = ".") +
  geom_boxplot() +
  geom_jitter(aes(color = na, alpha = 0.2))


pheno_df %>%
  mutate(
    na = case_when(
      is.na(ascvd_10y_accaha) ~ TRUE,
      !is.na(ascvd_10y_accaha) ~ FALSE
    )
  ) %>%
  filter(na == TRUE) %>%
  select(record_id, gender, smurfs, ascvd_10y_frs, chd_10y_mesa, SCORE2, ethcat, cacs, cacs_pct) %>%
  ggplot() + 
  aes(x = ascvd_10y_frs, y = log(cacs+1)) +
  geom_point() +
  theme_bw()


score_df %>%
  vis_miss()



# Drop all NA across all scores
score_df = score_df %>% drop_na(ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2_new)

```

Score Correlation

```{r}
# with the value labels
score_df %>%
  select(ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2_new) %>%
  cor() %>%
  corrplot::corrplot(method = "number", type = "upper", tl.col = "black", tl.srt = 45)


```

### Calculate Residuals

We calculated the studentised residuals which is also sometimes referred to as "externally studentised residuals" or "jack-knifed residuals". 

Other methods that were attempted included
* Diagonal residuals calculated perpendicular to the line of best fit for each score
* Harmonic Mean of vertical residuals from each risk score

#### Vertical Studentised Residuals

https://stats.stackexchange.com/questions/204708/is-studentized-residuals-v-s-standardized-residuals-in-lm-model

```{r}

# Calculate vertical residuals of linear model regressing CACS %tile on score
calculate_residuals = function(cacs_pct, score) {
  lm = lm(cacs_pct ~ score - 1) # forcing through zero
  return(residuals(lm))
}

# Calculate studentised vertial residuals of linear model regressing CACS %tile on score
studentised_residuals = function(cacs_pct, score) {
  lm = lm(cacs_pct ~ score - 1) # forcing through zero
  return(rstudent(lm))
}

```

```{r}

score_df = score_df %>%
  mutate(ln_cacs = log(cacs+1)) %>%
  mutate(
    res_ascvd_10y_frs = calculate_residuals(ln_cacs, ascvd_10y_frs),
    res_ascvd_10y_accaha = calculate_residuals(ln_cacs, ascvd_10y_accaha),
    res_chd_10y_mesa = calculate_residuals(ln_cacs, chd_10y_mesa),
    res_SCORE2 = calculate_residuals(ln_cacs, SCORE2)
  ) %>%
  mutate(
    studres_ascvd_10y_frs = studentised_residuals(ln_cacs, ascvd_10y_frs),
    studres_ascvd_10y_accaha = studentised_residuals(ln_cacs, ascvd_10y_accaha),
    studres_chd_10y_mesa = studentised_residuals(ln_cacs, chd_10y_mesa),
    studres_SCORE2 = studentised_residuals(ln_cacs, SCORE2)
  )

# Showing how many subjects have residuals of non-uniform sign
score_df %>%
  mutate(s = res_ascvd_10y_frs * res_ascvd_10y_accaha * res_chd_10y_mesa * res_SCORE2) %>%
  filter(s < 0)

```


### Calculating Zero-Inflated Regression Percentiles by Risk Score

#### Transformation and Standardisation

The following alternative is from Stuart's suggested method to standardise risk scores and take an average where possible.

````{r}

library(caret)

replace_non_na <- function(A, B) {
  # Find the indices of non-NA values in A
  non_na_indices <- which(!is.na(A))
  
  # Ensure B has enough values to replace non-NA values in A
  if (length(B) < length(non_na_indices)) {
    stop("Vector B does not have enough elements to replace all non-NA values in A")
  }
  
  # Replace non-NA values in A with values from B
  A[non_na_indices] <- B[seq_along(non_na_indices)]
  
  # Return the modified A
  return(A)
}

min_max_normalize <- function(x) {
  return((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}

standardise <- function(x) {
  return((x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))

}

# Normalizing the scores with Box-Cox Transformation
bc_trans = BoxCoxTrans(score_df$ascvd_10y_frs, na.rm=TRUE)
score_df$bc_ascvd_10y_frs = standardise(replace_non_na(score_df$ascvd_10y_frs, predict(bc_trans, score_df$ascvd_10y_frs)))
bc_trans = BoxCoxTrans(score_df$ascvd_10y_accaha, na.rm=TRUE)
score_df$bc_ascvd_10y_accaha = standardise(replace_non_na(score_df$ascvd_10y_accaha, predict(bc_trans, score_df$ascvd_10y_accaha)))
bc_trans = BoxCoxTrans(score_df$chd_10y_mesa, na.rm=TRUE)
score_df$bc_chd_10y_mesa = standardise(replace_non_na(score_df$chd_10y_mesa, predict(bc_trans, score_df$chd_10y_mesa)))
bc_trans = BoxCoxTrans(score_df$SCORE2_new, na.rm=TRUE)
score_df$bc_SCORE2_new = standardise(replace_non_na(score_df$SCORE2_new, predict(bc_trans, score_df$SCORE2_new)))

hist(score_df$bc_ascvd_10y_frs)
hist(score_df$bc_ascvd_10y_accaha)
hist(score_df$bc_chd_10y_mesa)
hist(score_df$bc_SCORE2_new)

# Applying normalization to each score column
score_df <- score_df %>%
  rowwise() %>%
  mutate(
    average_bc_score = mean(c_across(starts_with("bc_")), na.rm = TRUE)
  ) %>%
  ungroup()


score_df %>%
  # Select only columns starting with ordernorm
  select(record_id, ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2_new) %>%
  filter(record_id < 100) %>%
  pivot_longer(
    cols = c(ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2_new),
    names_to = "score",
    values_to = "value"
  ) %>%
  ggplot(aes(y = value, x = as.factor(record_id), color = score)) +
  geom_point() +
  theme_bw()


score_df %>%
  # Select only columns starting with ordernorm
  select(record_id, starts_with("bc_")) %>%
  filter(record_id < 100) %>%
  pivot_longer(
    cols = starts_with("bc_"),
    names_to = "score",
    values_to = "value"
  ) %>%
  ggplot(aes(y = value, x = as.factor(record_id), color = score)) +
  geom_point()

score_df %>%
  # Select only columns starting with ordernorm
  select(record_id, starts_with("bc_")) %>%
  #filter(record_id < 100) %>%
  pivot_longer(
    cols = starts_with("bc_"),
    names_to = "score",
    values_to = "value"
  ) %>%
  ggplot(aes(x = value, color = score)) +
  geom_freqpoly()

score_df %>% vis_miss()

# Normalizing the scores with orderNorm
score_df$ordernorm_ascvd_10y_frs = standardise(orderNorm(score_df$ascvd_10y_frs)$x.t)
score_df$ordernorm_ascvd_10y_accaha = standardise(orderNorm(score_df$ascvd_10y_accaha)$x.t)
score_df$ordernorm_chd_10y_mesa = standardise(orderNorm(score_df$chd_10y_mesa)$x.t)
score_df$ordernorm_SCORE2 = standardise(orderNorm(score_df$SCORE2_new)$x.t)

hist(score_df$ordernorm_ascvd_10y_frs)
hist(score_df$ordernorm_ascvd_10y_accaha)
hist(score_df$ordernorm_chd_10y_mesa)
hist(score_df$ordernorm_SCORE2)



# Normalizing the scores with just max min
score_df$ordernorm_ascvd_10y_frs = min_max_normalize(score_df$ascvd_10y_frs)
score_df$ordernorm_ascvd_10y_accaha = min_max_normalize(score_df$ascvd_10y_accaha)
score_df$ordernorm_chd_10y_mesa = min_max_normalize(score_df$chd_10y_mesa)
score_df$ordernorm_SCORE2 = min_max_normalize(score_df$SCORE2_new)


# Applying normalization to each score column
score_df <- score_df %>%
  rowwise() %>%
  mutate(
    average_norm_score = mean(c_across(starts_with("ordernorm_")), na.rm = TRUE)
  ) %>%
  ungroup()

score_df %>%
  # Select only columns starting with ordernorm
  select(record_id, starts_with("ordernorm_")) %>%
  filter(record_id < 100) %>%
  pivot_longer(
    cols = starts_with("ordernorm_"),
    names_to = "score",
    values_to = "value"
  ) %>%
  ggplot(aes(y = value, x = as.factor(record_id), color = score)) +
  geom_point() + 
  theme_bw()


score_df %>%
  # Select only columns starting with ordernorm
  select(record_id, starts_with("ordernorm_"), average_norm_score) %>%
  #filter(record_id < 100) %>%
  pivot_longer(
    cols = c(starts_with("ordernorm_"), average_norm_score),
    names_to = "score",
    values_to = "value"
  ) %>%
  ggplot(aes(x = value, color = score)) +
  geom_freqpoly() +
  theme_bw()
  
```

The following code is from Avanti & Sina.


Fits on Combined Average Normalised Score
```{r}

# Fits Zero Inflated model w/ only FRS Score

# 1 dropped because missing either CACS or average_norm_score need to investigate
score_df = score_df %>% drop_na(cacs, average_norm_score)
zeroinflmodel = zeroinfl(100*cacs ~ average_norm_score | average_norm_score, data = score_df, dist = "negbin")
summary(zeroinflmodel)


```

Fits on Single Score Normalised

```{r}

score_df = score_df %>% mutate(
    ordernorm_ascvd_10y_frs = orderNorm(ascvd_10y_frs)$x.t
)


# Fits Zero Inflated model w/ only FRS Score

zeroinflmodel = zeroinfl(100*cacs ~ ordernorm_ascvd_10y_frs | ordernorm_ascvd_10y_frs, data = score_df, dist = "negbin")
summary(zeroinflmodel)
```

Fits on Separate Scores Normalised

```{r}
# The following fits all the risk scores to a normal distribution, effectively meaning you care more about the ranks of the risk scores rather than the values. Also means you pay more emphasis to very high risk or very low risk.

score_df = score_df %>% mutate(
    ordernorm_ascvd_10y_frs = orderNorm(ascvd_10y_frs)$x.t,
    ordernorm_ascvd_10y_accaha = orderNorm(ascvd_10y_accaha)$x.t,
    ordernorm_chd_10y_mesa = orderNorm(chd_10y_mesa)$x.t,
    ordernorm_SCORE2 = orderNorm(SCORE2)$x.t
)


```

```{r}
# Fits Zero Inflated model w/ all scores

zeroinflmodel = zeroinfl(100*cacs ~ ordernorm_ascvd_10y_frs + ordernorm_ascvd_10y_accaha + ordernorm_chd_10y_mesa + ordernorm_SCORE2 | ordernorm_ascvd_10y_frs + ordernorm_ascvd_10y_accaha + ordernorm_chd_10y_mesa + ordernorm_SCORE2, data = score_df, dist = "negbin")
summary(zeroinflmodel)
```


```{r}
score_df = score_df %>% 
  mutate(
    # Predicted counts from the negative binomial part of the zero-inflated model
    # Based on the risk scores of a person, what should be their CACS
    cacs_riskscorecond_countpred = predict(zeroinflmodel, data=score_df, type="count") / 100,
    
    # Predicted probability of a zero result from the zero-inflated part of the model
    cacs_riskscorecond_zeroprob = predict(zeroinflmodel, data=score_df, type="zero"),
    
    # Overall predicted mean counts from the combined negative binomial & zero-inflated model
    cacs_riskscorecond_meanpred = predict(zeroinflmodel, data=score_df, type="response") / 100
  ) %>% 
  mutate(
    #The distribution is discrete, so for a given CACS value, I
    # will set the percentile to the mean of p(obs) <= CACS
    # and p(obs) < CACS i.e. add the two and divide by 2
    cacs_riskscorecond_pct = case_when(
      #when CACS > 0, p(obs) <= CACS and p(obs) < CACS both
      # include the probability that p(obs)==0 
      cacs > 0 ~ cacs_riskscorecond_zeroprob + (1 - cacs_riskscorecond_zeroprob) * 0.5 * (
        pnbinom(q = 100 * score_df$cacs, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred) +
        pnbinom(q = 100 * (score_df$cacs) - 1, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred)
      ),
      #when CACS==0, p(obs) <= CACS is just the probability
      # that p(obs)==0, because p(obs) < 0 is 0
      #Note that we can get an observation of zero either
      # because we are drawing from the zero inflation, or
      # because we are drawing from the counts model and the
      # counts model happened to generate a 0
      cacs == 0 ~ 0.5 * (cacs_riskscorecond_zeroprob + (1-cacs_riskscorecond_zeroprob)*pnbinom(q = 100 * score_df$cacs, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred))
    )
  )

```

```{r}

options(repr.plot.width = 15, repr.plot.height = 8)

plot_theme <- theme(
  legend.key.height = unit(2.5, "cm"),
  legend.title = element_text(size = 15, angle = 90),
  legend.title.align = 0.5,
  legend.direction = "vertical",
  text = element_text(size = 20)
)

plot_guide <- guides(
  size = "none", 
  colour = guide_colourbar(title.position = "right")
)

plot_zeroinflnegbinom_truevspredcacs <- ggplot(score_df, aes(
  x = log(1 + cacs_riskscorecond_meanpred),
  y = log(1 + cacs), 
  color = cacs_riskscorecond_pct
)) + 
  geom_point(size = 3) + 
  plot_guide + 
  plot_theme

plot_zeroinflnegbinom_cacspctvscacspred <- ggplot(score_df, aes(
  x = log(1 + cacs_riskscorecond_meanpred), 
  y = cacs_riskscorecond_pct,
  color = log(1 + cacs)
)) + 
  geom_point(size = 3) + 
  plot_guide + 
  plot_theme

grid.arrange(
  plot_zeroinflnegbinom_truevspredcacs, 
  plot_zeroinflnegbinom_cacspctvscacspred, 
  ncol = 2
)


```

### Calculating Zero-Inflated Regression Percentiles by Individual Variables

```{r}
df1 = dat_FRS %>%
  # Remove people with statin
  filter(!statin==1) %>%
  # Remove where gender or cac or cacs_pct not recorded
  drop_na(gender, cacs, cacs_pct) %>%
  # Ensure cacs is numeric and handle NAs
  mutate(cacs = as.numeric(cacs)) %>%
  filter(!is.na(cacs)) %>%
  # Calculate LDL and ln_cacs
  mutate(
    LDL = Chol - HDL
  ) %>%
  mutate(ln_cacs = log(cacs+1))


# Fits Zero Inflated model w/ only LDL

zeroinflmodel = zeroinfl(100*cacs ~ age | age, data = df1, dist = "negbin")
summary(zeroinflmodel)

```
```{r}
df1 = df1 %>% 
  mutate(
    # Predicted counts from the negative binomial part of the zero-inflated model
    cacs_riskscorecond_countpred = predict(zeroinflmodel, data=df1, type="count") / 100,
    
    # Predicted probability of a zero result from the zero-inflated part of the model
    cacs_riskscorecond_zeroprob = predict(zeroinflmodel, data=df1, type="zero"),
    
    # Overall predicted mean counts from the combined negative binomial & zero-inflated model
    cacs_riskscorecond_meanpred = predict(zeroinflmodel, data=df1, type="response") / 100
  ) %>% 
  mutate(
    #The distribution is discrete, so for a given CACS value, I
    # will set the percentile to the mean of p(obs) <= CACS
    # and p(obs) < CACS
    cacs_riskscorecond_pct = case_when(
      #when CACS > 0, p(obs) <= CACS and p(obs) < CACS both
      # include the probability that p(obs)==0 
      cacs > 0 ~ cacs_riskscorecond_zeroprob + (1 - cacs_riskscorecond_zeroprob) * 0.5 * (
        pnbinom(q = 100 * df1$cacs, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred) +
        pnbinom(q = 100 * (df1$cacs) - 1, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred)
      ),
      #when CACS==0, p(obs) <= CACS is just the probability
      # that p(obs)==0, because p(obs) < 0 is 0
      #Note that we can get an observation of zero either
      # because we are drawing from the zero inflation, or
      # because we are drawing from the counts model and the
      # counts model happened to generate a 0
      cacs == 0 ~ 0.5 * (cacs_riskscorecond_zeroprob +
        pnbinom(q = 100 * df1$cacs, size = zeroinflmodel$theta, mu = 100 * cacs_riskscorecond_countpred))
    )
  )

score_df = df1

```

```{r}

options(repr.plot.width = 15, repr.plot.height = 8)

plot_theme <- theme(
  legend.key.height = unit(2.5, "cm"),
  legend.title = element_text(size = 15, angle = 90),
  legend.title.align = 0.5,
  legend.direction = "vertical",
  text = element_text(size = 20)
)

plot_guide <- guides(
  size = "none", 
  colour = guide_colourbar(title.position = "right")
)

plot_zeroinflnegbinom_truevspredcacs <- ggplot(df1, aes(
  x = log(1 + cacs_riskscorecond_meanpred),
  y = log(1 + cacs), 
  color = cacs_riskscorecond_pct
)) + 
  geom_point(size = 3) + 
  plot_guide + 
  plot_theme

plot_zeroinflnegbinom_cacspctvscacspred <- ggplot(df1, aes(
  x = log(1 + cacs_riskscorecond_meanpred), 
  y = cacs_riskscorecond_pct,
  color = log(1 + cacs)
)) + 
  geom_point(size = 3) + 
  plot_guide + 
  plot_theme

grid.arrange(
  plot_zeroinflnegbinom_truevspredcacs, 
  plot_zeroinflnegbinom_cacspctvscacspred, 
  ncol = 2
)


```


### Classifying by Residuals

For each subject, the average studentised residual across all risk scores was used to classify the subject as either `resilient`, `susceptible`, `reference`, `ignore`.

* A reference cut-off is set e.g. 0.2
* The largest 20th percentile of negative residuals below the line of best fit (LOBF) is considered `resilient`
* The largest 20th percentile of positive residuals above the LOBF is considered `susceptible`
* The smallest 10th percentile of negative and positive residuals on either side of the LOBF is considered `reference`
* The rest of the subjects are categorised as `ignore`

#### Classification Functions 

```{r}
# Type 2 Classification - Absolute quantiles different for resilient and susceptible
# Find the quantiles for susceptible and resilient based on only residuals either positive or negative
calculate_classes_2 = function(residuals, lower_quantile_resilient, upper_quantile_resilient, lower_quantile_susceptible, upper_quantile_susceptible) {
  
  cohort_split = function(x) {
      if ((x >= upper_quantile_resilient) & (x <= lower_quantile_susceptible)) {
        return(as.factor("reference"))
      } else if (x < lower_quantile_resilient) {
        return(as.factor("resilient"))
      } else if (x > upper_quantile_susceptible){
        return(as.factor("susceptible"))
      } else {
        return(as.factor("ignore"))
      }
  }
  return(sapply(residuals, FUN = cohort_split))
  }

```

Externally studentised residuals. Importantly we assume the normality assumptions of the original model is met.

<https://stats.stackexchange.com/questions/204708/is-studentized-residuals-v-s-standardized-residuals-in-lm-model>

```{r}
score_df = score_df %>%
  rowwise() %>%
  mutate(avg_studres = mean(c(studres_ascvd_10y_frs, studres_ascvd_10y_accaha, studres_chd_10y_mesa, studres_SCORE2)))

reference_cutoff = 0.2

lower_quantile_resilient = quantile(score_df$avg_studres[score_df$avg_studres < 0], probs =   reference_cutoff)
upper_quantile_resilient = quantile(score_df$avg_studres[score_df$avg_studres < 0], probs =   1-reference_cutoff/2)
lower_quantile_susceptible = quantile(score_df$avg_studres[score_df$avg_studres > 0], probs =   reference_cutoff/2)
upper_quantile_susceptible = quantile(score_df$avg_studres[score_df$avg_studres > 0], probs =   1-reference_cutoff)

#cat(lower_quantile_resilient, ", ", upper_quantile_resilient, ", ", lower_quantile_susceptible, ", ", upper_quantile_susceptible, "\n")


score_df = score_df %>%
  mutate(
    consensus_class = calculate_classes_2(avg_studres, 
                                            lower_quantile_resilient, 
                                            upper_quantile_resilient, 
                                            lower_quantile_susceptible, 
                                            upper_quantile_susceptible)
  )


score_df$stud_class = score_df$consensus_class
write.csv(score_df, "score_df.csv")
```

The following show the results of the groupings.

```{r}
table(score_df$consensus_class)
```

* The graph below shows the plots of `ln(CACS+1)` against the various risk scores. 
* The colours represent the classifications made based on the average studentised residuals across all the risk scores.


```{r}
long_score_df = score_df %>%
  dplyr::select(-starts_with("studres")) %>%
  pivot_longer(cols = c("ascvd_10y_frs", "ascvd_10y_accaha", "chd_10y_mesa", "SCORE2"), names_to = "score_type", values_to = "score") %>%
  mutate(score_type = as.factor(score_type))


# create a list of unique score types
score_types = unique(long_score_df$score_type)

# create a plot for each score type
plots = lapply(score_types, function(score_type) {
  # subset the data for the current score type
  df_subset = long_score_df[long_score_df$score_type == score_type,]
  # create the plot
  #ggplot(df_subset, aes(x = score, y = cacs_pct)) +
  ggplot(df_subset, aes(x=score, y=ln_cacs)) +
    geom_point(aes(color = consensus_class)) +
    geom_smooth(formula = y ~ x - 1, method = 'lm', se = FALSE) +
    theme_bw() +
    labs(title = paste("CACS vs", score_type),
         x = "Score Value", y = "ln(CACS+1)")
})

# arrange the plots in a grid
p = gridExtra::grid.arrange(grobs = plots, ncol = 2, nrow = 2)
# ggsave("~/Desktop/myplot.png", plot = p, width = 12, height = 8, dpi = 300)
ggsave("myplot.png", plot = p, width = 12, height = 8, dpi = 300)
```

### Classifying by Z-Score binned by Risk Score (Alternative)

```{r}
colnames(score_df)
score_df = score_df %>%
  mutate(ln_cacs = log(cacs+1))

# Assuming score_df is your dataset and ascvd_10y_frs is your risk score column.
score_df = score_df %>% drop_na(ascvd_10y_frs)

# Assuming score_df is your dataset and ascvd_10y_accaha is your risk score column.
#score_df = score_df %>% drop_na(ascvd_10y_accaha)


# 1. Bin subjects into 10 bins by risk score
# Define the range for the risk score to be binned
bin_range = seq(min(score_df$ascvd_10y_frs), max(score_df$ascvd_10y_frs), length.out = 11)
score_df$bin = cut(score_df$ascvd_10y_frs, breaks = bin_range, include.lowest = TRUE, labels = FALSE)

# 2. Calculate z-score for cacs score within each bin
score_df = score_df %>%
  group_by(bin) %>%
  mutate(mean_cacs = mean(ln_cacs, na.rm = TRUE),
         sd_cacs = sd(ln_cacs, na.rm = TRUE),
         z_score = (ln_cacs - mean_cacs) / sd_cacs) %>%
  ungroup()

# 3. Create consensus_class factor column
score_df$consensus_class = case_when(
  score_df$z_score < -1 ~ "resilient",
  score_df$z_score > 1 ~ "susceptible",
  abs(score_df$z_score) <= 0.5 ~ "reference",
  TRUE ~ "ignore"
)

# Convert to factor for plotting purposes, setting 'reference' as the reference level
score_df$consensus_class = factor(score_df$consensus_class, levels = c("reference", "resilient", "susceptible", "ignore"))

# 4. Graph cacs against ascvd_10y_frs risk score
ggplot(score_df, aes(x = ascvd_10y_frs, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  geom_vline(xintercept = bin_range, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs ASCVD 10y FRS Risk Score", x = "ASCVD 10y FRS Risk Score", y = "ln(CACS+1)", color = "Consensus Class")

table(score_df$consensus_class)

```

```{r}
ggplot(score_df) +
  aes(y=z_score, x=ascvd_10y_frs, color = consensus_class) +
  geom_point() +
  theme_bw() +
  labs(title = "ln(CACS+1) Z-Score vs ASCVD 10y FRS Risk Score", x = "ASCVD 10y FRS Risk Score", y = "Z-Score", color = "Consensus Class")

```
You can see a concerning number of people who are old, with no CACS that our model considers "not resilient"

```{r}
score_df %>% 
  inner_join(dat_FRS, by=c('ID')) %>%
  ggplot(aes(x = age, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  geom_vline(xintercept = bin_range, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs Age", x = "Age", y = "ln(CACS+1)", color = "Consensus Class")

```

### Classifying by Z-Score binned by Individual Variable (Alternative)

```{r}
colnames(score_df)
df1 = dat_FRS %>%
  # Remove people with statin
  filter(!statin==1) %>%
  # Remove where gender or cac or cacs_pct not recorded
  drop_na(gender, cacs, cacs_pct) %>%
  # Ensure cacs is numeric and handle NAs
  mutate(cacs = as.numeric(cacs)) %>%
  filter(!is.na(cacs)) %>%
  # Calculate LDL and ln_cacs
  mutate(
    LDL = Chol - HDL
  ) %>%
  mutate(ln_cacs = log(cacs+1))

# 1. Bin subjects into 10 bins by risk score
# Define the range for the risk score to be binned
bin_range = seq(min(df1$LDL), max(df1$LDL), length.out = 11)
df1$bin = cut(df1$LDL, breaks = bin_range, include.lowest = TRUE, labels = FALSE)

# 2. Calculate z-score for cacs score within each bin
df1 = df1 %>%
  group_by(bin) %>%
  mutate(mean_cacs = mean(ln_cacs, na.rm = TRUE),
         sd_cacs = sd(ln_cacs, na.rm = TRUE),
         z_score = (ln_cacs - mean_cacs) / sd_cacs) %>%
  ungroup()

# 3. Create consensus_class factor column
df1$consensus_class = case_when(
  df1$z_score < -1 ~ "resilient",
  df1$z_score > 1 ~ "susceptible",
  abs(df1$z_score) <= 0.5 ~ "reference",
  TRUE ~ "ignore"
)

# Convert to factor for plotting purposes, setting 'reference' as the reference level
df1$consensus_class = factor(df1$consensus_class, levels = c("reference", "resilient", "susceptible", "ignore"))

# 4. Graph cacs against ascvd_10y_frs risk score
ggplot(df1, aes(x = LDL, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  geom_vline(xintercept = bin_range, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs ASCVD 10y FRS Risk Score", x = "ASCVD 10y FRS Risk Score", y = "ln(CACS+1)", color = "Consensus Class")

table(df1$consensus_class)

```

```{r}
ggplot(score_df) +
  aes(y=z_score, x=ascvd_10y_frs, color = consensus_class) +
  geom_point() +
  theme_bw() +
  labs(title = "ln(CACS+1) Z-Score vs ASCVD 10y FRS Risk Score", x = "ASCVD 10y FRS Risk Score", y = "Z-Score", color = "Consensus Class")

```

You can see a concerning number of people who are old, with no CACS that our model considers "not resilient"

```{r}
score_df %>% 
  inner_join(dat_FRS, by=c('ID')) %>%
  ggplot(aes(x = age, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  geom_vline(xintercept = bin_range, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs Age", x = "Age", y = "ln(CACS+1)", color = "Consensus Class")

```

### Classifying by Zero-Inflated Regression Percentiles by Risk Score

```{r}

score_df$consensus_class = case_when(
  score_df$cacs_riskscorecond_pct < 0.20 ~ "resilient",
  score_df$cacs_riskscorecond_pct > 0.80 ~ "susceptible",
  ((score_df$cacs_riskscorecond_pct > 0.40) & (score_df$cacs_riskscorecond_pct < 0.60))  ~ "reference",
  TRUE ~ "ignore"
)

score_df %>% select(consensus_class, cacs_riskscorecond_pct)

ggplot(score_df, aes(x = average_norm_score, y = cacs, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "CACS vs Average Normalised Score", x = "Average Normalised Score", y = "CACS", color = "Consensus Class")



ggplot(score_df, aes(x = ordernorm_ascvd_10y_frs, y = cacs_riskscorecond_pct, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "CACS Percentile (Risk Adjusted) vs Normalised ASCVD 10y FRS Risk Score", x = "Normalised ASCVD 10y FRS Risk Score", y = "CACS Percentile (Risk Adjusted)", color = "Consensus Class")

ggplot(score_df, aes(x = average_norm_score , y = cacs_riskscorecond_pct, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "CACS Percentile (Risk Adjusted) vs Average Normalised Score", x = "Average Normalised Score", y = "CACS Percentile (Risk Adjusted)", color = "Consensus Class")

# Convert to factor for plotting purposes, setting 'reference' as the reference level
score_df$consensus_class = factor(score_df$consensus_class, levels = c("reference", "resilient", "susceptible", "ignore"))

table(score_df$consensus_class)

# Resilient vs Other
# score_df = score_df %>%
#   mutate(consensus_class = case_when(
#     consensus_class == "ignore" ~ "other",
#     consensus_class == "reference" ~ "other",
#     consensus_class == "susceptible" ~ "other",
#     TRUE ~ "resilient"
#   ))


write.csv(score_df, "resilience.csv")
```
### Classifying by Zero-Inflated Regression Percentiles by Individual Variables

```{r}

df1$consensus_class = case_when(
  df1$cacs_riskscorecond_pct < 0.20 ~ "resilient",
  df1$cacs_riskscorecond_pct > 0.80 ~ "susceptible",
  ((df1$cacs_riskscorecond_pct > 0.40) & (df1$cacs_riskscorecond_pct < 0.60))  ~ "reference",
  TRUE ~ "ignore"
)

df1 %>% select(consensus_class, cacs_riskscorecond_pct)

ggplot(df1, aes(x = age, y = cacs, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "CACS vs Age", x = "Age", y = "CACS", color = "Consensus Class")

ggplot(df1, aes(x = age, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs Age", x = "Age", y = "ln(CACS+1)", color = "Consensus Class")

ggplot(df1, aes(x = age, y = cacs_riskscorecond_pct, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "CACS Percentile (Age Adjusted) vs Age", x = "Age", y = "CACS Percentile (Age Adjusted)", color = "Consensus Class")

# Convert to factor for plotting purposes, setting 'reference' as the reference level
df1$consensus_class = factor(score_df$consensus_class, levels = c("reference", "resilient", "susceptible", "ignore"))

score_df = df1
table(df1$consensus_class)


```

```{r}

df1 %>% 
  ggplot(aes(x = age, y = ln_cacs, color = consensus_class)) +
  geom_point() +
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  theme_bw() +
  labs(title = "ln(CACS+1) vs Age", x = "Age", y = "ln(CACS+1)", color = "Consensus Class")

```
### Comparing Classes


```{r, warning=FALSE}
# Metabolomics
# Picks the first assay rlmSampleAllShort_H_batch
metab_exp = longFormat(bioheart_mae[,,'Metabolomics'],
                 colDataCols = c("gender","age", "smurfs", "cacs", "cacs_pct", "gensini"),
                 i = 3L)

metab_df = data.frame(metab_exp) %>%
  filter(primary != "Pool") %>%
  pivot_wider(id_cols = c(primary, colname, gender, age, smurfs, cacs, cacs_pct, gensini), 
              names_from = rowname, values_from = value) %>%
  filter(if_all(everything(), ~ .!=".")) %>%
  transform(cacs = as.numeric(cacs), cacs_pct = as.numeric(cacs_pct), gensini = as.numeric(gensini), primary = as.numeric(primary)) %>%
  # Remove duplicate rows, .keep_all <- keeps all of the rest of columns
  distinct(primary, .keep_all = TRUE) %>%
  drop_na() #%>%
  #mutate(across(8:60, ~(.-min(.))/((max(.)-min(.)))))

graph_df = score_df %>%
  dplyr::select(record_id, consensus_class) %>%
  inner_join(metab_df, by=c('record_id'='primary')) # %>%
  #filter(consensus_class %in% c("resilient", "reference"))

# Graph Box Plot
graph_df %>%
  pivot_longer(cols = -c(record_id, gender, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini), names_to = "metabolite", values_to = "value") %>%
  ggplot() +
  aes(x = metabolite, y = value, colour = consensus_class) +
  geom_boxplot() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

```{r}


# PCA Analysis
metab_pca = graph_df %>%
  select(-c(ID, consensus_class, colname, gender, age, smurfs, cacs, cacs_pct, gensini)) %>%
  #scale() %>%
  prcomp()

fviz_eig(metab_pca, addlabels = TRUE)

fviz_pca_ind(metab_pca,
             geom.ind = "point",
             col.ind = graph_df %>% select(consensus_class) %>% pull(),
             palette = c("#00AFBB", "#E7B800", "#FC4E07", "#000000"),
             addEllipses = TRUE,
             legend.title = "Groups")

metab_pca_limited = graph_df %>%
  filter(gender == 1) %>%
  filter(age > 60) %>%
  select(-c(ID, consensus_class, colname, gender, age, smurfs, cacs, cacs_pct, gensini)) %>%
  #scale() %>%
  prcomp()


fviz_pca_ind(metab_pca_limited,
             geom.ind = "point",
             col.ind = graph_df %>% filter(gender == 1) %>% filter(age > 60) %>% select(consensus_class) %>% pull(),
             palette = c("#00AFBB", "#E7B800", "#FC4E07", "#000000"),
             addEllipses = TRUE,
             legend.title = "Groups")

fviz_pca_ind(metab_pca_limited,
             geom.ind = "point",
             col.ind = graph_df %>% filter(gender == 1) %>% filter(age > 60) %>% select(cacs_pct) %>% pull(),
             gradient.cols = c("green", "red"),
             legend.title = "Groups")
```

##### Differential Expression Analysis

The contrasts are `resilient` - `reference`.

```{r, warning=FALSE}
filtered_graph_df = graph_df #%>%
  #filter(gender == 1) %>%
  #filter(age > 60) 
lm_df = filtered_graph_df %>%
  dplyr::select(-c(record_id, consensus_class, colname, gender, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

design = model.matrix(~ consensus_class, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)

# Contrasts
#CM = makeContrasts(consensus_classresilient = consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classcomparison = consensus_classsusceptible - consensus_classresilient, levels = design)
CM = makeContrasts(consensus_classsusceptible = consensus_classsusceptible, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit)
```

```{r, warning=FALSE}
# Volcano Plot
library(EnhancedVolcano)
p = EnhancedVolcano(
  constrast_fit,
  lab = rownames(constrast_fit),
  x = "coefficients",
  y = "p.value",
  title = "Resilient vs Reference (un-adjusted p-values)",
  pCutoff = 0.05,
  labSize = 6
)

ggsave("resilient_reference_volcano.png", plot = p, width = 12, height = 8, dpi = 300)

# MA Plot
glMDPlot(constrast_fit,
         counts = lm_df,
         coef=1, 
         main= "Resilient v.s. Reference",
         groups = filtered_graph_df$consensus_class,
         html="resilient_reference_ma_plot.html")

```


##### Top-50 CAC vs no-CAC

No we compare the patients with the highest CAC (n=50) to those with no CAC to see if the results earlier are simply a product of patients having very high CAC.

The contrasts are `high_cac` - `no_cac`.

```{r, warning=FALSE}
filtered_graph_df = graph_df
filtered_graph_df$cacs_rank = rank(-graph_df$cacs, ties.method = "min")
filtered_graph_df = filtered_graph_df %>%
  mutate(cacs_bool = factor(case_when(
    cacs_rank <= 50 ~ "high_cac",
    cacs_pct == 0 ~ "no_cac",
    TRUE ~ "ignore")
  ))

filtered_graph_df$cacs_bool = relevel(filtered_graph_df$cacs_bool, "no_cac")

unique(filtered_graph_df$cacs_bool)
lm_df = filtered_graph_df %>%
  dplyr::select(-c(ID, consensus_class, colname, gender, age, smurfs, cacs, cacs_pct, gensini, cacs_bool, cacs_rank)) %>%
  t()

table(filtered_graph_df$cacs_bool)


design = model.matrix(~ cacs_bool, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)


library(Glimma)

# Contrasts
CM = makeContrasts(cacs_boolhigh_cac, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit)

# Volcano Plot
#library(EnhancedVolcano)
#p = EnhancedVolcano(
#  constrast_fit,
#  lab = rownames(constrast_fit),
#  x = "coefficients",
#  y = "p.value",
#  title = "Top 50 CACS vs Zero CACs (un-adjusted p-values)",
#  pCutoff = 0.05,
#  labSize = 6
#)
#
#
#ggsave("cac_no_cac_volcano.png", plot = p, width = 12, height = 8, dpi = 300)
#
## MA Plot
#glMDPlot(constrast_fit,
#         counts = lm_df,
#         coef=1, 
#         main= "High CACS (Top 50) v.s. Zero CACS",
#         groups = filtered_graph_df$cacs_bool,
#         html="high_cacs_top_50_zero_cacs_ma_plot.html")
#
#
#
#constrast_fit$p.value
```

#### Lipidomics

Lipid Species.

```{r, warning=FALSE}

# Picks the first assay rlmSampleAllShort_H_batch
lipid_species_exp = longFormat(bioheart_mae[,,'Lipidomics_species'],
                 colDataCols = c("age", "smurfs", "cacs", "cacs_pct", "gensini"),
                 i = 2L)

lipid_species_df = data.frame(lipid_species_exp) %>%
  filter(primary != "Pool") %>%
  pivot_wider(id_cols = c(primary, colname, age, smurfs, cacs, cacs_pct, gensini), 
              names_from = rowname, values_from = value) %>%
  transform(cacs = as.numeric(cacs), cacs_pct = as.numeric(cacs_pct), gensini = as.numeric(gensini), primary = as.numeric(primary))

graph_df = score_df %>%
  select(record_id, consensus_class) %>%
  inner_join(lipid_species_df, by=c('record_id'='primary'))

#score_df %>%
#  select(ID, consensus_class) %>%
#  inner_join(lipid_species_df, by=c('ID'='primary')) %>%
#  filter(consensus_class %in% c("resilient", "reference")) %>%
#  pivot_longer(cols = -c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini), names_to = "lipid_species", values_to = #"value") %>%
#  ggplot() +
#  aes(x = lipid_species, y = value, colour = consensus_class) +
#  geom_boxplot() +
#  theme_bw() +
#  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

Lipid Totals.

```{r, warning=FALSE}
lipid_totals_exp = longFormat(bioheart_mae[,,'Lipidomics_totals'],
                 colDataCols = c("age", "smurfs", "cacs", "cacs_pct", "gensini"),
                 i = 2L)

lipid_totals_df = data.frame(lipid_totals_exp) %>%
  filter(primary != "Pool") %>%
  pivot_wider(id_cols = c(primary, colname, age, smurfs, cacs, cacs_pct, gensini), 
              names_from = rowname, values_from = value) %>%
  transform(cacs = as.numeric(cacs), cacs_pct = as.numeric(cacs_pct), gensini = as.numeric(gensini), primary = as.numeric(primary))

graph_df = score_df %>%
  select(record_id, consensus_class) %>%
  inner_join(lipid_totals_df, by=c('record_id'='primary'))

score_df %>%
  select(record_id, consensus_class) %>%
  inner_join(lipid_totals_df, by=c('record_id'='primary')) %>%
  filter(consensus_class %in% c("resilient", "reference")) %>%
  pivot_longer(cols = -c(record_id, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini), names_to = "lipid_total", values_to = "value") %>%
  ggplot() +
  aes(x = lipid_total, y = value, colour = consensus_class) +
  geom_boxplot() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

##### Differential Expression Analysis

```{r, warning=FALSE}
filtered_graph_df = graph_df #%>%
  #filter(gender == 1) %>%
  #filter(age > 60) 
lm_df = filtered_graph_df %>%
  dplyr::select(-c(record_id, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

design = model.matrix(~ consensus_class, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)

```

The contrasts are `resilient` - `reference`.

```{r, warning=FALSE}

# Contrasts
#CM = makeContrasts(consensus_classresilient = consensus_classresilient, levels = design)
CM = makeContrasts(consensus_classcompare = consensus_classresilient - consensus_classreference, levels = design)
#CM = makeContrasts(consensus_classsusceptible = consensus_classsusceptible, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit, n=50)

```

```{r, warning=FALSE}

# Contrasts
#CM = makeContrasts(consensus_classresilient = consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classcompare = consensus_classsusceptible - consensus_classresilient, levels = design)
CM = makeContrasts(consensus_classsusceptible = consensus_classsusceptible, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit, n=50)

```

Here we dive deeper into some specific lipid groups. However, we've been told at this point that the elevation of Ceramides / Triglycerides is unlikely to be a marker of resilience and more likely to be a product of large risk score patients selected.

```{r, warning=FALSE}

score_df %>%
  select(ID, consensus_class) %>%
  inner_join(lipid_totals_df %>%
               select(primary, colname, age, smurfs, cacs, cacs_pct, gensini, `Cer.m.`, `TG.SIM.`,`TG..NL.`)
             , by=c('ID'='primary')) %>%
  #filter(consensus_class %in% c("resilient", "reference")) %>%
  pivot_longer(cols = -c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini), names_to = "lipid_total", values_to = "value") %>%
  ggplot() +
  aes(x = lipid_total, y = value, colour = consensus_class) +
  geom_boxplot(notch=TRUE) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


```

#### Proteomics

```{r, warning=FALSE}



# From the BioHEART MAE

prot_exp = longFormat(bioheart_mae[,,'Proteomics'],
                 colDataCols = c("age", "smurfs", "cacs", "cacs_pct", "gensini"))


prot_df = data.frame(prot_exp) %>%
  filter(!grepl("Repeat", colname)) %>%
  filter(primary != "79") %>%
  filter(primary != "Pool") %>%
  filter(primary != "Pool") %>%
  pivot_wider(id_cols = c(primary, age, smurfs, cacs, cacs_pct, gensini), 
              names_from = rowname, values_from = value) %>%
  transform(cacs = as.numeric(cacs), cacs_pct = as.numeric(cacs_pct), gensini = as.numeric(gensini), primary = as.numeric(primary))

#score_df %>%
#  select(ID, consensus_class) %>%
#  inner_join(prot_df, by=c('ID'='primary')) %>%
#  filter(consensus_class %in% c("resilient", "reference")) %>%
#  pivot_longer(cols = -c(ID, consensus_class, age, smurfs, cacs, cacs_pct, gensini), names_to = "proteins", values_to = "value") %>%
#  ggplot() +
#  aes(x = proteins, y = value, colour = consensus_class) +
#  geom_boxplot() +
#  theme_bw() +
#  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

Comparing the BioHEART dataset I inherited to the new dataset from a datalock. Not exactly sure why they are different.

```{r}
# From the Data Lock

df1 = BioHRT_dat %>% select(-c( bioheart_id, clinical_site, disc_1000, r1000, dup_enrolment, dup_enrolment_num, age, age_f, gender, ethcat, ethcat_dual, height, weight, bmi, smurfs, cvhx_dm, diabetes_type, diabetes_years, diabetes_notes, cvhx_htn, cvhx_htn_notes, cvhx_hcl_sr_or_statin, cvhx_hcl_sr, cvhx_hcl_notes, cvhx_angina, cvhx_angina_notes, cvhx_mi, cvhx_mi_notes, cvhx_rhythm_svt, cvhx_rhythm_aflutter, cvhx_rhythm_af, cvhx_rhythm_notes, cvhx_hf, cvhx_hf_notes, cvhx_stent, cvhx_stent_notes, cvhx_cabg, cvhx_cabg_notes, cvhx_heartsx_other, cvhx_heartsx_other_desc, cvhx_cardiacprob_other, cvhx_cardiacprob_other_desc, mhx_arthritis, mhx_arthritis_ra, mhx_arthritis_osteo, mhx_arthritis_gout, mhx_arthritis_other, mhx_arthritis_other_desc, mhx_arthritis_notes, mhx_osteoporosis_osteopenia, mhx_osteoporosis_notes, mhx_stroke, mhx_stroke_notes, mhx_pad, mhx_pad_notes, mhx_dvt_pe, mhx_dvt_pe_notes, mhx_kidney, mhx_kidney_notes, mhx_other, mhx_other_desc, fh_ihd, fh_ihd_sex, fh_ihd_age, fh_clottingdisorders, fh_clottingdisorders_desc, medication_yn, noac, warfarin, anti_coag, asa, clopidogrel, ticagrelor, prasugrel, anti_plt, statin, ezetimibe, pcsk9, fibrate, niacin, babr, plant_sterol, lipid_lowering_unknown, bblocker, ace_arb, ace_i, arb, ccb, diuretic, diur_loop, diur_thiazide, diur_k, diur_non_thiazide, diur_unk, anti_arrhythmic, ivabradine, ppi, antiinflammatory, anti_diab, metformin, sglt2, glp, dpp4, su, insulin, diab_unk, specific_medication, smoking_status, signif_smok, curr_smok, pack_years, years_quit_smoking, drinking_status, drinks_per_week, years_abstinence, primary_occupation, exposure_to_heavy_metals, specific_heavy_metal, city_lived_in_longest, post_code, pet_owner, pet_type, sx_cp, sx_sob, sx_palp, sx_fatigue, sx_other, sx_other_desc, sx_acute, sx_ed, sbp, dbp, hr, stat_rate_ctrl, creatinine, egfr, ctca_ind_gen_cv_assessment, ctca_ind_sx, ctca_ind_ecg, ctca_ind_fh_ihd, ctca_ind_congenital_coronary, ctca_ind_surg, ctca_ind_other, ctca_ind_other_desc, bloods_fast, withdraw_no_fu, withdraw_full, cacs_iapl1, cacs_pct_pooled_iapl1, cacs, cacs_pct, gensini, mgens, sps_v, sps_d, mha, apoa1, apoa2, tc, ldl, hdl, tgl, nt_bnp, bnp, gal3, hs_trop, cl, hco3, cr, crp, glucose, k, lpa, na, urea))


df2 = prot_df %>% select(-c(age, smurfs, cacs, cacs_pct, gensini))


library(dplyr)

# Standardize column names
names(df1) <- tolower(names(df1))
names(df2) <- tolower(names(df2))

# Identify matching columns (excluding ID columns)
common_cols <- intersect(setdiff(names(df1), "record_id"), setdiff(names(df2), "primary"))

# Join by ID
merged <- df1 %>%
  rename(id = record_id) %>%
  inner_join(df2 %>% rename(id = primary), by = "id", suffix = c("_df1", "_df2"))

# Add match flags
for (col in common_cols) {
  merged[[paste0(col, "_match")]] <- merged[[paste0(col, "_df1")]] != merged[[paste0(col, "_df2")]]
}

# Keep rows where at least one mismatch
mismatched_rows <- merged %>%
  filter(if_any(ends_with("_match"), ~ . == TRUE))

# Rearranged output: ID, then alternating df1 / df2 columns for each variable
side_by_side_cols <- c("id", unlist(lapply(common_cols, function(col) {
  c(paste0(col, "_df1"), paste0(col, "_df2"))
})))

output <- mismatched_rows %>% select(all_of(side_by_side_cols))

print(output)


# Prepare long format for plotting
plot_df <- merged %>%
  select(id, all_of(unlist(lapply(common_cols, function(col) c(paste0(col, "_df1"), paste0(col, "_df2")))))) %>%
  pivot_longer(
    cols = -id,
    names_to = c("metabolite", "source"),
    names_pattern = "(.*)_(df1|df2)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = source,
    values_from = value
  )

# Take only first 5 metabolites
first5 <- unique(plot_df$metabolite)[1:9]
plot_subset <- filter(plot_df, metabolite %in% first5)

# Plot
plots <- lapply(first5, function(met) {
  ggplot(filter(plot_subset, metabolite == met), aes(x = df1, y = df2)) +
    geom_point(alpha = 0.7) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    labs(title = paste("Scatter plot of:", met),
         x = "df1 value",
         y = "df2 value") +
    theme_minimal()
})

# Display plots
library(gridExtra)
grid.arrange(grobs = plots, ncol = 3)
colnames(output)

write.csv(df2, "proteomics.csv")

```

##### Differential Expression Analysis

```{r, warning=FALSE}

prot_patient_df = score_df %>%
  select(record_id, consensus_class, average_norm_score) %>%
  # Remove outlier 1067
  #filter(record_id != 1067) %>%
  inner_join(prot_df, by=c('record_id'='primary'))
setdiff(score_df$record_id, prot_df$primary)

lm_df = prot_patient_df %>%
  select(-c(record_id, consensus_class, age, smurfs, cacs, cacs_pct, gensini, average_norm_score)) %>%
  t()

design = model.matrix(~ consensus_class, prot_patient_df)

fit = lmFit(lm_df, design)
fit = eBayes(fit)
topTable(fit)

#CM = makeContrasts(consensus_classresilient = consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classcompare = consensus_classsusceptible - consensus_classresilient, levels = design)
CM = makeContrasts(consensus_classsusceptible = consensus_classsusceptible, levels = design)
constrast_fit = contrasts.fit(fit, contrast = CM)
constrast_fit = eBayes(constrast_fit)
topTable(constrast_fit, n=500)
table(score_df$consensus_class)


prot_patient_df %>%
  summarise(mean(GC))
```
Find zeros

```{r}
zero_test = prot_df %>% select(-c(primary, age, smurfs, cacs, cacs_pct, gensini))
colSums(zero_test == 0, na.rm = TRUE)

```


```{r}

signif_igs = c("IGLV7-43;IGLV7-46", "IGHM", "IGKV2-29;IGKV2-30;IGKV2D-29", "IGKV2-29;IGKV2D-29")

# Immunoglobulins vs CACS Percentile

prot_patient_df %>%
  select(cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs_pct, average_norm_score)) %>%
  filter(consensus_class == "resilient") %>%
  ggplot() +
  aes(x = cacs_pct, y = value, colour = protein) +
  geom_point() +
  theme_bw() +
  labs(title = "Immunoglobulins vs CACS Percentile", x = "CACS Percentile", y = "Immunoglobulins")


prot_patient_df %>%
  select(cacs_pct, `IGLV7-43;IGLV7-46`, consensus_class, average_norm_score) %>%
  filter(consensus_class == "resilient") %>%
  ggplot() +
  aes(x = average_norm_score, y = `IGLV7-43;IGLV7-46`) +
  geom_point() +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")

# Immunoglobulins vs Average Normalised Score

prot_patient_df %>%
  select(cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs_pct, average_norm_score)) %>%
  filter(consensus_class == "resilient") %>%
  ggplot() +
  aes(x = average_norm_score, y = value, color = protein) +
  geom_point() +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")


prot_patient_df %>%
  select(cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs_pct, average_norm_score)) %>%
  filter(consensus_class %in% c("resilient", "susceptible")) %>%
  ggplot() +
  aes(x = average_norm_score, y = value, color = consensus_class, shape = protein) +
  geom_point() +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")


is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

prot_patient_df %>%
  select(record_id, cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  filter(consensus_class %in% c("resilient", "reference", "susceptible")) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(record_id, consensus_class, cacs_pct, average_norm_score)) %>%
  mutate(outlier = ifelse(is_outlier(value), record_id, as.numeric(NA))) %>%
  ggplot() +
  aes(x = consensus_class, y = value, color = consensus_class) +
  facet_wrap(~protein)+
  geom_boxplot(notch=TRUE) +
  geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3) +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")


# with the value labels
prot_patient_df %>%
  select(signif_igs) %>%
  cor() %>%
  corrplot::corrplot(method = "number", type = "upper", tl.col = "black", tl.srt = 45)

# Immunoglobulins vs ln(CACS+1)

prot_patient_df %>%
  select(cacs, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs, average_norm_score)) %>%
  filter(consensus_class %in% c("resilient", "susceptible")) %>%
  ggplot() +
  aes(x = log(cacs+1), y = value, colour = consensus_class) +
  facet_wrap(~protein, scales = "free") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw() +
  labs(title = "Immunoglobulins vs ln(CACS+1)", x = "ln(CACS+1)", y = "Immunoglobulins")

library(ggpubr)
library(ggthemes)

# Immunoglobulins vs ln(CACS+1)

prot_patient_df %>%
  select(cacs, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs, average_norm_score)) %>%
  filter(consensus_class %in% c("resilient", "susceptible")) %>%
  mutate(ln_cacs = log(cacs+1)) %>%
  ggscatter(
    x = "ln_cacs", y = "value",
    color = "consensus_class", palette = "jco",
    cor.coef = TRUE
    ) +
    geom_smooth(method = "lm", color = "black") +
    facet_wrap(~protein, scales = "free") +
    labs(title = "Immunoglobulins vs ln(CACS+1)", x = "ln(CACS+1)", y = "Immunoglobulins")

# Immunoglobulins vs Average Normalised Score

prot_patient_df %>%
  select(cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(consensus_class, cacs_pct, average_norm_score)) %>%
  filter(consensus_class %in% c("resilient", "susceptible")) %>%
  ggscatter(
    x = "average_norm_score", y = "value",
    color = "consensus_class", palette = "jco",
    cor.coef = TRUE
    ) +
    geom_smooth(method = "lm", color = "black") +
    facet_wrap(~protein, scales = "free") +
    labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")
```


Immunoglobulins Analysis

```{r}
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

prot_patient_df %>%
  select(record_id, cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  filter(consensus_class %in% c("resilient", "reference", "susceptible")) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(record_id, consensus_class, cacs_pct, average_norm_score)) %>%
  mutate(outlier = ifelse(is_outlier(value), record_id, as.numeric(NA))) %>%
  ggplot() +
  aes(x = consensus_class, y = value, color = consensus_class) +
  facet_wrap(~protein) +
  geom_boxplot(notch = TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "black", position = position_dodge(width = 0.75)) +
  geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3) +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", x = "Average Normalised Score", y = "Immunoglobulins")

# Outlier Plot for Immunoglobulins
prot_patient_df %>%
  select(record_id, cacs_pct, signif_igs, consensus_class, average_norm_score) %>%
  filter(consensus_class %in% c("resilient", "reference", "susceptible")) %>%
  pivot_longer(names_to = "protein", values_to = "value", -c(record_id, consensus_class, cacs_pct, average_norm_score)) %>%
  mutate(
    outlier_flag = ifelse(is_outlier(value), "outlier", "normal"),
    outlier_label = ifelse(outlier_flag == "outlier", record_id, NA)
  ) %>%
  ggplot(aes(x = consensus_class, y = value, color = consensus_class)) +
  facet_wrap(~protein) +
  geom_boxplot(notch = TRUE, outlier.shape = NA) +
  geom_jitter(aes(shape = outlier_flag), alpha = 0.7, size = 2, width = 0.2) +
  geom_text(aes(label = outlier_label), 
            na.rm = TRUE,
            position = position_jitter(width = 0.2, height = 0), 
            hjust = -0.3, size = 4) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "black", position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c("normal" = 16, "outlier" = 17)) +
  theme_bw() +
  labs(title = "Immunoglobulins vs Average Normalised Score", 
       x = "Consensus Class", 
       y = "Immunoglobulin Value")


# Correlation between Immunoglobulins
prot_patient_df %>%
  select(signif_igs) %>%
  cor() %>%
  corrplot::corrplot(method = "number", type = "upper", tl.col = "black", tl.srt = 45)



# Log(CACS+1) vs Average Normalised Score
score_df %>%
  select(cacs, average_norm_score, consensus_class) %>%
  ggplot() +
  aes(x = average_norm_score , y = log(cacs + 1), color = consensus_class) +
  geom_point() +
  theme_bw()

```



```{r}
BioHRT_dat %>% filter(bioheart_id == "CT_1067") %>% select(record_id, cacs, cacs_pct, gensini, age, gender, smurfs, bmi, cvhx_dm, cvhx_htn, cvhx_mi, cvhx_hcl_sr, mhx_other_desc, fh_ihd, fh_ihd_sex, fh_ihd_age, ace_arb, arb, statin, diuretic, signif_smok, pack_years, sbp, dbp, hr, lpa)
hist(prot_patient_df %>% filter(consensus_class == "resilient") %>% pull(`IGLV7-43;IGLV7-46`))
```


```{r}
score_df %>% 
  select(ascvd_10y_frs, ascvd_10y_accaha, chd_10y_mesa, SCORE2) %>%
  cor(use = "complete.obs")

```

```{r}

# Volcano Plot
library(EnhancedVolcano)
p = EnhancedVolcano(
  topTable(constrast_fit, n=500),
  lab = rownames(topTable(constrast_fit, n=500)),
  x = "logFC",
  y = "adj.P.Val",
  title = "Resilient vs Reference",
  FCcutoff = 0.10,
  pCutoff = 0.05,
  labSize = 6,
  xlim = c(-0.5,0.5),
  ylim = c(0, 3),
  drawConnectors = TRUE,
  subtitle = "",
)

ggsave("resilient_reference_volcano.png", plot = p, width = 12, height = 8, dpi = 300)

p = EnhancedVolcano(
  topTable(constrast_fit, n=500),
  lab = rownames(topTable(constrast_fit, n=500)),
  x = "logFC",
  y = "adj.P.Val",
  title = "Susceptible vs Reference",
  FCcutoff = 0.10,
  pCutoff = 0.05,
  labSize = 6,
  xlim = c(-0.5,0.5),
  ylim = c(0, 3),
  drawConnectors = TRUE,
  subtitle = "",
)

ggsave("susceptible_reference_volcano.png", plot = p, width = 12, height = 8, dpi = 300)

#Volcano Plot
library(EnhancedVolcano)
p = EnhancedVolcano(
  constrast_fit,
  lab = rownames(constrast_fit),
  x = "coefficients",
  y = "p.value",
  title = "Resilient vs Reference",
  FCcutoff = 0.25,
  labSize = 6
)

p

ggsave("resilient_reference_volcano.png", plot = p, width = 12, height = 8, dpi = 300)

# MA Plot
glMDPlot(constrast_fit,
         counts = lm_df,
         coef=1, 
         main= "Resilient v.s. Reference",
         groups = filtered_graph_df$consensus_class,
         html="resilient_reference_ma_plot.html")


```

Get IDs of resilient SMURFless patients.

```{r}

export = score_df %>%
  filter(consensus_class == "resilient") %>%
  left_join(dat_FRS %>% select(ID, smurfs), by=c( 'record_id' = 'ID')) %>%
  filter(smurfs == 0)

write.csv(export, "resilient_smurfless.csv")

```

#### CyTOF

```{r}
score_df %>% pull(record_id)
```


```{r, warning=FALSE}
# Picks the first assay rlmSampleAllShort_H_batch
exp = longFormat(bioheart_mae[,,'CyTOF'],
                 colDataCols = c("age", "smurfs", "cacs", "cacs_pct", "gensini"),
                 i = 1L)


cytof_df = data.frame(exp) %>%
  filter(primary != "Pool") %>%
  mutate(primary = as.double(primary)) %>%
  pivot_wider(id_cols = c(primary, colname, age, smurfs, cacs, cacs_pct, gensini), names_from = rowname, values_from = value) %>%
  transform(cacs = as.numeric(cacs), cacs_pct = as.numeric(cacs_pct), gensini = as.numeric(gensini)) %>%
  drop_na

cytof_patient_df = score_df %>%
  select(record_id, consensus_class) %>%
  inner_join(cytof_df, by=c('record_id'='primary')) %>%
  select(-colname)

design = model.matrix(~ consensus_class, cytof_patient_df)

lm_df = cytof_patient_df %>%
  select(-c(record_id, consensus_class, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

fit = lmFit(lm_df, design)
fit = eBayes(fit)
topTable(fit)



CM = makeContrasts(consensus_classresilient = consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classcompare = consensus_classsusceptible - consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classsusceptible = consensus_classsusceptible, levels = design)
constrast_fit = contrasts.fit(fit, contrast = CM)
constrast_fit = eBayes(constrast_fit)
topTable(constrast_fit)


```



```{r}
# Export score_df as .csv
write.csv(score_df, "score_df.csv", row.names = FALSE)
```


### Summary Table

```{r}

library(gtsummary)
library(writexl)

colnames(pheno_df)

pheno_df = pheno_df %>%
  mutate(gensini_bin = case_when(
    gensini == 0 ~ 0,
    gensini > 0 ~ 1
  ))

pheno_df = pheno_df %>%
  merge(score_df, by="record_id")

rsk_factors <- c("age","smurfs","cvhx_htn","cvhx_dm","cvhx_hcl_sr",
              "signif_smok", "curr_smok", "anti_coag",
              "anti_plt", "statin", "bblocker", "ace_arb",
              "bmi", "fh_ihd", "gender")


gt_res <- pheno_df %>%
  dplyr::select(all_of(c("gensini_bin", rsk_factors, "smurfs", "consensus_class"))) %>%
  mutate(SMuRFless = ifelse(smurfs == 0, 1, 0)) %>%
  tbl_summary(by=consensus_class) %>% 
  add_n() %>%
  add_overall() %>%
  add_p() %>% # test for a difference between groups
  modify_header(label = "**Consensus Class**") # update the column header

gt_res %>%
  gtsummary::as_tibble() %>% 
  writexl::write_xlsx(., "summary_table.xlsx")

print(gt_res)
```


### Why are we seeing SMuRFless in the Resilient Group?
```{r}
test_df = pheno_df %>%
  left_join(score_df, by="record_id") %>%
  mutate(SMuRFless = ifelse(smurfs == 0, 1, 0)) %>%
  mutate(weird = ifelse((consensus_class.x == "resilient") & (SMuRFless == 1), TRUE, FALSE))

ggplot(test_df, aes(x = ordernorm_ascvd_10y_frs.x, y = cacs_riskscorecond_pct.x, color = consensus_class.x)) +
  # Points for all data
  geom_point(aes(shape = weird), size = 2) +
  
  # Custom shape and color for weird == TRUE
  geom_point(data = subset(test_df, weird == TRUE), aes(x = ordernorm_ascvd_10y_frs.x, y = cacs_riskscorecond_pct.x), 
             shape = 17, color = "orange", size = 3) +
  
  # Add labels for points where weird == TRUE
  geom_text(data = subset(test_df, weird == TRUE), aes(x = ordernorm_ascvd_10y_frs.x, y = cacs_riskscorecond_pct.x, label = record_id), 
            vjust = -1, hjust = 0.5, color = "orange") +
  
  # Manual color scaling for consensus_class
  scale_color_manual(values = c("resilient" = "green", "reference" = "blue", "susceptible" = "red", "ignore" = "grey50")) +
  
  # Add labels, theme, and title
  theme_bw() +
  labs(title = "CACS Percentile (Risk Adjusted) vs Normalised ASCVD 10y FRS Risk Score", 
       x = "Normalised ASCVD 10y FRS Risk Score", 
       y = "CACS Percentile (Risk Adjusted)", 
       color = "Consensus Class", shape = "Weird")

pheno_df %>%
  left_join(score_df, by="record_id") %>%
  mutate(SMuRFless = ifelse(smurfs == 0, 1, 0)) %>%
  filter((consensus_class.x == "resilient") & (SMuRFless == 1)) %>%
  select(gender, age, HDL_mgdl, Chol_mgdl, sbp, bp_med, curr_smok, cvhx_dm, ascvd_10y_frs.x, ascvd_10y_accaha.x, chd_10y_mesa.x, SCORE2.x, SCORE2_new, consensus_class.x, SMuRFless)

```


#### Targeted Analysis

The following metabolites, proteins, cell counts etc. were selected based on literature and were related to resilience in some way. We performed targeted analysis on these variables by selecting them alone from separate individual datasets.

*dat_FRS*
* `CRP`
* `LP(a)`
* `LDL-C`

*Proteomics*
* `SERPINA3`
* `APOB` <- better LDL measurement
* `FN1`
____
* `C7`
* `LBP`
* `SERPINF2`

*Lipidomics Species*
* `Cer.d18.1.24.1.` / `Cer.d18.1.24.0.`
* `Cer.d18.1.16.0.` / `PC.16.0_22.6.`
* `PC.16.0_16.0.`
* `Cer.d18.1.16.0.`
* `Cer.d18.1.18.0.`
* `Cer.d18.1.24.0.`
* `Cer.d18.1.24.1.`

*CyTOF*
* `Treg %CD4`
* `Treg %total`
* `14+ monos %myeloids`
* `16+ monos %myeloids`

##### Proteomics

```{r, warning=FALSE}

single_prot_df = prot_df %>%
  select(c(primary, age, smurfs, cacs, cacs_pct, gensini, FN1))

prot_patient_df = score_df %>%
  select(ID, consensus_class) %>%
  inner_join(single_prot_df, by=c('ID'='primary'))


prot_patient_df %>%
  ggplot(aes(x = consensus_class, y = FN1)) +
  geom_boxplot(notch=TRUE) +
  theme_bw()


lm_df = prot_patient_df %>%
  select(-c(ID, consensus_class, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

design = model.matrix(~ consensus_class, prot_patient_df)


fit = lmFit(lm_df, design)
fit = eBayes(fit)
topTable(fit)

CM = makeContrasts(consensus_classresilient = consensus_classresilient - consensus_classreference, levels = design)
constrast_fit = contrasts.fit(fit, contrast = CM)
constrast_fit = eBayes(constrast_fit)
topTable(constrast_fit)


```
##### Lipidomics

```{r, warning=FALSE}

species_interest = c("Cer.d18.1.24.1./Cer.d18.1.24.0.", "Cer.d18.1.16.0./PC.16.0_22.6.", 'PC.16.0_16.0.', 'Cer.d18.1.16.0.', 'Cer.d18.1.18.0.', 'Cer.d18.1.24.0.', 'Cer.d18.1.24.1.')

graph_df = score_df %>%
  select(ID, consensus_class) %>%
  inner_join(lipid_species_df, by=c('ID'='primary'))

graph_df = graph_df %>%
  mutate(
    "Cer.d18.1.24.1./Cer.d18.1.24.0." = `Cer.d18.1.24.1.`/`Cer.d18.1.24.0.`,
    "Cer.d18.1.16.0./PC.16.0_22.6." = `Cer.d18.1.16.0.` / `PC.16.0_22.6.`
  )

filtered_graph_df = graph_df %>%
  select(c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini, all_of(species_interest)))

# Boxplot by species of interest
p = filtered_graph_df %>%
  select(c("consensus_class", species_interest)) %>%
  tidyr::pivot_longer(cols = species_interest, names_to = "species", values_to = "value") %>%
  ggplot(aes(x = consensus_class, y = value, fill = consensus_class)) +
  geom_boxplot(notch = TRUE) +
  facet_wrap(~ species, scales = "free_y") +
  labs(x = "Consensus Class", y = "Value") +
  theme_bw()
p
ggsave("boxplot.png", plot = p, width = 12, height = 8, dpi = 300)


lm_df = filtered_graph_df %>%
  dplyr::select(-c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

design = model.matrix(~ consensus_class, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)

# Contrasts
CM = makeContrasts(consensus_classresilient = consensus_classresilient - consensus_classreference, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classreference, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit)
```

##### CyTOF

You can see here that the class sizes are far too small to draw any reasonable conclusion.

```{r, warning=FALSE}
species_interest = c("Treg..CD4", "Treg..total", "X14..monos..myeloids", "X16..monos..myeloids")

filtered_graph_df = cytof_patient_df %>%
  select(c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini, all_of(species_interest)))

# Boxplot by species of interest
p = filtered_graph_df %>%
  select(c("consensus_class", species_interest)) %>%
  tidyr::pivot_longer(cols = species_interest, names_to = "species", values_to = "value") %>%
  ggplot(aes(x = consensus_class, y = value, fill = consensus_class)) +
  geom_boxplot(notch = TRUE) +
  facet_wrap(~ species, scales = "free_y") +
  labs(x = "Consensus Class", y = "Value") +
  theme_bw()
p
ggsave("boxplot.png", plot = p, width = 12, height = 8, dpi = 300)

table(filtered_graph_df$consensus_class)

lm_df = filtered_graph_df %>%
  dplyr::select(-c(ID, consensus_class, colname, age, smurfs, cacs, cacs_pct, gensini)) %>%
  t()

design = model.matrix(~ consensus_class, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)

# Contrasts
CM = makeContrasts(consensus_classresilient = consensus_classresilient - consensus_classreference, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classreference, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit)
```



##### dat-FRS

Averages where there are multiple measurements in the case of CRP and LP(a)

```{r, warning=FALSE}


species_interest = c("CRP","LP(a)")

dat_FRS_patient_df = score_df %>%
  select(ID, consensus_class) %>%
  inner_join(dat_FRS, by=c('ID'='ID'))


# Function to compute average from a character string of numbers
compute_average <- function(x) {
    # Split string into individual numbers, convert to numeric, and compute average
    mean(as.numeric(unlist(strsplit(x, split = ",\\s*"))), na.rm = TRUE)
}

# Pick species of interest and if there are multiple measurements to average
filtered_graph_df = dat_FRS_patient_df %>%
  select(c(ID, consensus_class, all_of(species_interest))) %>%
  drop_na() %>%
  mutate(
        CRP = sapply(CRP, compute_average),
        `LP(a)` = sapply(`LP(a)`, compute_average)
    )

# Boxplot by species of interest
p = filtered_graph_df %>%
  select(c("consensus_class", species_interest)) %>%
  tidyr::pivot_longer(cols = species_interest, names_to = "species", values_to = "value") %>%
  ggplot(aes(x = consensus_class, y = value, fill = consensus_class)) +
  geom_boxplot(notch = TRUE) +
  facet_wrap(~ species, scales = "free_y") +
  labs(x = "Consensus Class", y = "Value") +
  theme_bw()
p
ggsave("boxplot.png", plot = p, width = 12, height = 8, dpi = 300)

table(filtered_graph_df$consensus_class)

lm_df = filtered_graph_df %>%
  dplyr::select(-c(ID, consensus_class)) %>%
  t()

design = model.matrix(~ consensus_class, filtered_graph_df)
fit = lmFit(lm_df, design)
efit = eBayes(fit)
topTable(efit)

# Contrasts
CM = makeContrasts(consensus_classresilient = consensus_classresilient - consensus_classreference, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classresilient, levels = design)
#CM = makeContrasts(consensus_classresilient = consensus_classsusceptible - consensus_classreference, levels = design)
constrast_fit = contrasts.fit(efit, contrast = CM)
constrast_fit = eBayes(constrast_fit)

topTable(constrast_fit)
```

#### SNPs

```{r}
# Load the biomaRt library
library(biomaRt)

#rsids = scan("rsIDs.txt", what = "character")
rsids = scan("cd39.txt", what = "character")

# Select the human SNP mart
snpMart = useMart(biomart = "ENSEMBL_MART_SNP", dataset = "hsapiens_snp")

# List of rsIDs
#rsids = c("rs11207977", "rs186021206", "rs145297799", "rs3135506", "rs115849089", "rs1122608", "rs111245230", "rs11591147", "rs12916")  # replace with your actual rsIDs

# Get chromosome and position
results = getBM(attributes = c("refsnp_id", "chr_name", "chrom_start"), 
                 filters = "snp_filter", 
                 values = rsids, 
                 mart = snpMart)

# Add a column for the end position, which is the same as the start position for SNPs
results$chrom_end = results$chrom_start
# Assuming df is your existing dataframe
results$label = paste0("R", 1:nrow(results))



# Write the results to a text file
write.table(results[, c("chr_name", "chrom_start", "chrom_end", "label")], 
            file = "myranges.txt", 
            sep = "\t", 
            quote = FALSE, 
            row.names = FALSE, 
            col.names = FALSE)


```


```{r}
genotypes = read.csv("genotypes.raw", sep='')
mapping = read.csv("mapping.txt", header = FALSE)

genotypes = genotypes %>%
  left_join(mapping, by = c("IID" = "V2")) %>%
  mutate(BioHEART_ID = as.numeric(sub("^BH_", "", V1)))


snps_info = read.table("extracted_snps.bim")

# results is chromosome and position of enquired snps from ENSEMBL_MART_SNP
snp_labels = results %>%
  filter(chrom_start %in% snps_info$V4) %>%
  pull(refsnp_id)


genotype_columns = grep("chr[0-9XY]+\\.[0-9]+\\.[ACGT]\\.[ACGT]_[ACGT]", names(genotypes), value = TRUE)
names(genotypes)[match(genotype_columns, names(genotypes))] = snp_labels

snp_score_df = score_df %>%
  inner_join(genotypes, by=c('record_id'='BioHEART_ID')) %>%
  select_if(~ !anyNA(.))
```
```{r}
snp_score_df %>%
  select(rs186021206, V1)
```

```{r}

vis_miss(genotypes)
vis_miss(snp_score_df)
```

```{r}

rs_columns = grep("^rs", names(snp_score_df), value = TRUE)

rs_columns

# Resilient versus Reference
analyze_columns = function(df, rs_columns) {
  # Filter rows where consensus_class is either "resilience" or "reference"
  df <- df %>% filter(consensus_class %in% c("resilient", "reference"))
  # Drop unused levels
  df$consensus_class <- droplevels(df$consensus_class, except = c("resilient", "reference"))
  
  results = list()
  for (col in rs_columns) {
    # Create a contingency table
    contingency_table = table(df[[col]], df$consensus_class)
    print(contingency_table)
    # Apply Fisher's exact test
    fisher_test = fisher.test(contingency_table, workspace = 2e6)
    
    # Store the results
    results[[col]] = list(
      summary = contingency_table,
      fisher_test = fisher_test
    )
  }
  
  return(results)
}

# Resilient versus Everything
analyze_columns = function(df, rs_columns) {
  # Filter rows where consensus_class is "reference", "resilient", "ignore", or "susceptible"
  df <- df %>% filter(consensus_class %in% c("resilient", "reference", "ignore", "susceptible"))
  
  # Recode the "resilient", "ignore", and "susceptible" levels to "other"
  df$consensus_class <- recode(df$consensus_class, "reference" = "other", "ignore" = "other", "susceptible" = "other")

  # Drop unused levels
  df$consensus_class <- droplevels(df$consensus_class)

  results = list()
  for (col in rs_columns) {
    # Create a contingency table
    contingency_table = table(df[[col]], df$consensus_class)
    print(contingency_table)
    # Apply Fisher's exact test
    fisher_test = fisher.test(contingency_table, workspace = 2e6)
    
    # Store the results
    results[[col]] = list(
      summary = contingency_table,
      fisher_test = fisher_test
    )
  }
  
  return(results)
}

# Resilient versus Reference
analyze_columns = function(df, rs_columns) {
  # Filter rows where consensus_class is "reference", "resilient", "ignore", or "susceptible"
  df <- df %>% filter(consensus_class %in% c("resilient", "reference"))

  # Drop unused levels
  df$consensus_class <- droplevels(df$consensus_class)

  results = list()
  for (col in rs_columns) {
    # Create a contingency table
    contingency_table = table(df[[col]], df$consensus_class)
    print(contingency_table)
    # Apply Fisher's exact test
    fisher_test = fisher.test(contingency_table, workspace = 2e6)
    
    # Store the results
    results[[col]] = list(
      summary = contingency_table,
      fisher_test = fisher_test
    )
  }
  
  return(results)
}

# Resilient versus Reference
analyze_columns = function(df, rs_columns) {
  # Filter rows where consensus_class is "reference", "resilient", "ignore", or "susceptible"
  df <- df %>% filter(consensus_class %in% c("resilient", "susceptible"))

  # Drop unused levels
  df$consensus_class <- droplevels(df$consensus_class)

  results = list()
  for (col in rs_columns) {
    # Create a contingency table
    contingency_table = table(df[[col]], df$consensus_class)
    print(contingency_table)
    # Apply Fisher's exact test
    fisher_test = fisher.test(contingency_table, workspace = 2e6)
    
    # Store the results
    results[[col]] = list(
      summary = contingency_table,
      fisher_test = fisher_test
    )
  }
  
  return(results)
}


results = analyze_columns(snp_score_df, rs_columns)
results

```

#### SNPs New

```{r}

#Plate ID to BioHEART Mapping
mapping = read.csv("mapping.txt", header = FALSE)

mapping_clean = mapping %>%
  rename(c("record_id" = "V1", "IID" = "V2")) %>%
  mutate(record_id = str_remove(record_id, "BH_")) %>%
  mutate(record_id = str_remove(record_id, "CT_")) %>%
  mutate(record_id = as.numeric(record_id))

pheno_df = score_df %>%
  left_join(dat_FRS %>% dplyr::select(record_id, age, gender), by = c("record_id")) %>%
  left_join(mapping_clean, by = c("record_id")) %>%
  dplyr::select("IID", "age", "gender", "consensus_class", "cacs_pct") %>%
  drop_na()

# Only if you wish to compare resilient to EVERYONE ELSE
pheno_df = pheno_df %>%
  mutate(consensus_class = case_when(
    consensus_class == "susceptible" ~ "other",
    consensus_class == "reference" ~ "other",
    consensus_class == "ignore" ~ "other",
    TRUE ~ "resilient"
  ))

write_tsv(pheno_df, "pheno.tsv")
```

Now go to Obsidian where the code for running the SNP analysis is.

```{r}
resilient_reference_snps = read_tsv("output_file.consensus_class.glm.logistic.hybrid")

```

```{r}

# Load the biomaRt library
library(biomaRt)

rsids = scan("cd39.txt", what = "character")


ensembl = useEnsembl(biomart = "snps")

listDatasets(ensembl)

# Select the human SNP mart
snpMart = useEnsembl(biomart = "snps", dataset = "hsapiens_snp")

# List of rsIDs
#rsids = c("rs11207977", "rs186021206", "rs145297799", "rs3135506", "rs115849089", "rs1122608", "rs111245230", "rs11591147", "rs12916")  # replace with your actual rsIDs

# Get chromosome and position
results = getBM(attributes = c("refsnp_id", "chr_name", "chrom_start"), 
                 filters = "snp_filter", 
                 values = rsids, 
                 mart = snpMart)

results = results %>%
  rename(c(
    "CHROM" = "chr_name",
    "POS" = "chrom_start"
  )) %>%
  mutate(CHROM = as.integer(CHROM)) %>%
  drop_na()

results$refsnp_id
```

```{r}
rsids[!rsids %in% results$refsnp_id]

```

```{r}
resilient_reference_snps = resilient_reference_snps %>%
  rename(c("CHROM" = "#CHROM")) %>%
  mutate(CHROM = as.integer(CHROM),
         POS = as.integer(POS))
  
results %>%
  left_join(resilient_reference_snps) %>%
  write.csv("resilient_other_snps.csv")



library(magrittr)
resilient_reference_snps %>%
  mutate(p.adjust = p.adjust(P %>% as.vector, method = "fdr")) %>%
  filter(p.adjust < 0.05)
```



## Individual Variable Model of Resilience

```{r}
# Changing Code

df1 = dat_FRS %>%
  # Remove people with statin
  filter(!statin==1) %>%
  # Remove where gender or cac or cacs_pct not recorded
  drop_na(gender, cacs, cacs_pct) %>%
  # Ensure cacs is numeric and handle NAs
  mutate(cacs_pct = as.numeric(cacs_pct)) %>%
  filter(!is.na(cacs_pct)) %>%
  # Calculate LDL and ln_cacs
  mutate(
    LDL = Chol - HDL
  ) %>%
  # calculate residuals
  mutate(
    res_ldl = calculate_residuals(cacs_pct, LDL),
  ) %>%
  # calculate studentised residuals
  mutate(
    studres_ldl = studentised_residuals(cacs_pct, LDL)
  )

```

```{r}

reference_cutoff = 0.2

lower_quantile_resilient = quantile(df1$studres_ldl[df1$studres_ldl < 0], probs =   reference_cutoff)
upper_quantile_resilient = quantile(df1$studres_ldl[df1$studres_ldl < 0], probs =   1-reference_cutoff/2)
lower_quantile_susceptible = quantile(df1$studres_ldl[df1$studres_ldl > 0], probs =   reference_cutoff/2)
upper_quantile_susceptible = quantile(df1$studres_ldl[df1$studres_ldl > 0], probs =   1-reference_cutoff)



df1 = df1 %>%
  mutate(
    consensus_class = calculate_classes_2(studres_ldl, 
                                            lower_quantile_resilient, 
                                            upper_quantile_resilient, 
                                            lower_quantile_susceptible, 
                                            upper_quantile_susceptible)
  )


df1$stud_class = df1$consensus_class
score_df = df1

```

```{r}
df1 %>%
  ggplot(aes(x = LDL, y = cacs_pct)) +
  geom_point(aes(color = consensus_class)) +
  geom_smooth(formula = y ~ x - 1, method = 'lm', se = FALSE) +
  theme_bw() +
  labs(title = paste("CACS vs non-HDL Cholesterol"),
       x = "non-HDL Cholesterol", y = "CACS (%tile)")

```



Randopm
```{r}

score_df %>%
  filter(consensus_class == "resilient") %>%
  left_join(pheno_df, by = c("record_id" = "record_id")) %>%
  filter(smurfs == 0)

pheno_df
```

